{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This code is part of the SIPN2 project focused on improving sub-seasonal to seasonal predictions of Arctic Sea Ice. \n",
    "If you use this code for a publication or presentation, please cite the reference in the README.md on the\n",
    "main page (https://github.com/NicWayand/ESIO). \n",
    "\n",
    "Questions or comments should be addressed to nicway@uw.edu\n",
    "\n",
    "Copyright (c) 2018 Nic Wayand\n",
    "\n",
    "GNU General Public License v3.0\n",
    "\n",
    "\n",
    "'''\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import os\n",
    "import xarray as xr\n",
    "import glob\n",
    "# import loadobservations as lo\n",
    "from esio import import_data\n",
    "from esio import metrics\n",
    "from esio import EsioData as ed\n",
    "from esio import ice_plot\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import dask\n",
    "import timeit\n",
    "import xesmf as xe\n",
    "\n",
    "\n",
    "# Dirs\n",
    "E = ed.EsioData.load()\n",
    "data_dir = E.obs_dir\n",
    "\n",
    "# Flags\n",
    "UpdateAll = True\n",
    "\n",
    "# Products to import\n",
    "product_list = ['iceBridgeQuickLook']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-threads is fastest for this script\n",
    "dask.config.set(scheduler='threads')  # overwrite default with threaded scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'conservative_normed' # ['bilinear', 'conservative', 'nearest_s2d', 'nearest_d2s', 'patch']\n",
    "UpdateAll = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each product\n",
    "for c_product in product_list:\n",
    "    print('Importing ', c_product, '...')\n",
    "    start_pt = 0 # Starting index\n",
    "\n",
    "    # Find new files that haven't been imported yet\n",
    "    native_dir = os.path.join(data_dir, c_product, 'native')\n",
    "    os.chdir(native_dir)\n",
    "    \n",
    "    native_files = sorted(glob.glob('*.txt'))\n",
    "    nc_dir = os.path.join(data_dir, c_product, 'sipn_nc')\n",
    "\n",
    "    os.chdir(nc_dir)\n",
    "    nc_files = sorted(glob.glob('*.nc'))\n",
    "    \n",
    "    if UpdateAll:\n",
    "        new_files = [x.split('.txt')[0] for x in native_files]\n",
    "        print('Updating all ', len(native_files), ' files...')\n",
    "    else:\n",
    "        new_files = np.setdiff1d([os.path.basename(x).split('.txt')[0] for x in native_files], \n",
    "                                 [x.split('.nc')[0] for x in nc_files]) # just get file name and compare\n",
    "        print('Found ', len(new_files), ' new files to import...')\n",
    "\n",
    "    # Loop through each file\n",
    "    for nf in new_files:\n",
    "        print(nf)\n",
    "        \n",
    "        # Load in \n",
    "        ds = import_data.load_1_iceBridgeQL(filein=os.path.join(native_dir, nf+'.txt'), start_pt=start_pt)\n",
    "        \n",
    "        # Save last point value\n",
    "        start_pt = ds.point.values[-1]\n",
    "        \n",
    "        # Save to netcdf file\n",
    "        ds.to_netcdf(os.path.join(nc_dir, nf+'.nc'))\n",
    "        ds = None\n",
    "    \n",
    "    # For each Product\n",
    "    print(\"Finished \", c_product)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid point data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- Quality control using uncertainty thresholds (SIT uncertainty < 0.15 m)\n",
    "- Grid to polar stereographic grid (~25km by ~25 km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB_unc_threshold = 0.15 # m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.15*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IceBridge Quick Look\n",
    "ds_all = xr.open_mfdataset(os.path.join(E.obs_dir, 'iceBridgeQuickLook', 'sipn_nc', '*.nc'), concat_dim='point')\n",
    "ds_all.set_coords(['date','lat','lon'], inplace=True)\n",
    "# Shift lon to -180 to 180 space\n",
    "ds_all['lon'] = ((ds_all.lon+180)%360)-180\n",
    "# Remove points where lat is greater than 90 or less than 50 (recoding error I assume...)\n",
    "ds_all = ds_all.where(ds_all.lat<=90, drop=True)\n",
    "ds_all = ds_all.where(ds_all.lat>=50, drop=True)\n",
    "\n",
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hi unc for 2018 flights (0.8 m)\n",
    "ds_all.where(ds_all.date>np.datetime64('2018-01-01'), drop=True).hi_unc.mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all.where(ds_all.date>np.datetime64('2018-01-01'), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(ds_all.hi_unc.values, ds_all.hi.values,'k*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_all.hi_unc.plot()\n",
    "# ds_all.hi.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_all.mean_fb.plot()\n",
    "# ds_all.fb_unc.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_all.fb_unc.plot.hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove SIC values with high uncertainty\n",
    "ds_all['hi'] = ds_all.hi.where(ds_all.fb_unc <= FB_unc_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target grid\n",
    "stero_grid_file = E.obs['NSIDC_0051']['grid']\n",
    "obs_grid = import_data.load_grid_info(stero_grid_file, model='NSIDC')\n",
    "# Ensure latitude is within bounds (-90 to 90)\n",
    "# Have to do this because grid file has 90.000001\n",
    "obs_grid['lat_b'] = obs_grid.lat_b.where(obs_grid.lat_b < 90, other = 90)\n",
    "# Format for use here\n",
    "#obs_grid = obs_grid.rename({'lat':'latitude','lon':'longitude'})[['latitude','longitude']]\n",
    "`obs_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = sorted(list(set(ds_all.date.values)), reverse=True)\n",
    "print(len(unique_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stuff\n",
    "ds_all.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xemsf method of regridding\n",
    "\n",
    "cvar = 'hi'\n",
    "for cdate in unique_dates:\n",
    "    print(cdate)\n",
    "    \n",
    "    # Output file path\n",
    "    f_o = os.path.join(E.obs_dir, 'iceBridgeQuickLook', 'sipn_nc_grid', 'IB_'+pd.to_datetime(cdate).strftime('%Y-%m-%d')+'.nc')\n",
    "    \n",
    "    # Check if we already imported it\n",
    "    if not UpdateAll:\n",
    "        if os.path.isfile(f_o):\n",
    "            print(\"Skipping \", os.path.basename(f_o), \" already imported.\")\n",
    "            continue # Skip, file already imported\n",
    "    \n",
    "    # Grab icebridge data from current date (what we want to grid)\n",
    "    X1 = ds_all[cvar].where(ds_all.date==cdate, drop=True)\n",
    "    X2 = X1.where(X1.notnull(), drop=True)\n",
    "    if X2.point.size==0:\n",
    "        continue\n",
    "        \n",
    "\n",
    "    \n",
    "    # Build ds_fine\n",
    "    ds_fine = None\n",
    "    \n",
    "    m_res = 1000 # X meters\n",
    "    deg_res = np.cos(np.deg2rad(X2.lat.mean().values))*111.321*1000\n",
    "    tar_res = m_res / deg_res\n",
    "\n",
    "    lat_arr = np.arange(X2.lat.min().values,X2.lat.max().values,tar_res)\n",
    "    lon_arr = np.arange(X2.lon.min().values,X2.lon.max().values,tar_res)\n",
    "\n",
    "    lat_arr_b = np.arange(X2.lat.min().values-tar_res/2,X2.lat.max().values+tar_res/2,tar_res)\n",
    "    lon_arr_b = np.arange(X2.lon.min().values-tar_res/2,X2.lon.max().values+tar_res/2,tar_res)\n",
    "\n",
    "    ds_cvar = xr.DataArray(np.ones((len(lat_arr),len(lon_arr))) * np.nan, dims=('y','x'))\n",
    "\n",
    "\n",
    "    lonmesh, latmesh = np.meshgrid(lon_arr, lat_arr)\n",
    "    lonmesh = xr.DataArray(lonmesh, dims=('y','x'))\n",
    "    latmesh = xr.DataArray(latmesh, dims=('y','x'))\n",
    "    #\n",
    "    lonmesh_b, latmesh_b = np.meshgrid(lon_arr_b, lat_arr_b)\n",
    "    lonmesh_b = xr.DataArray(lonmesh_b, dims=('y_b','x_b'))\n",
    "    latmesh_b = xr.DataArray(latmesh_b, dims=('y_b','x_b'))\n",
    "\n",
    "    y_arr = xr.DataArray(np.arange(0,len(lat_arr),1), dims=('y'))\n",
    "    x_arr = xr.DataArray(np.arange(0,len(lon_arr),1), dims=('x'))\n",
    "    #\n",
    "    y_arr_b = xr.DataArray(np.arange(0,len(lat_arr_b),1), dims=('y_b'))\n",
    "    x_arr_b = xr.DataArray(np.arange(0,len(lon_arr_b),1), dims=('x_b'))\n",
    "\n",
    "    ds_fine = xr.Dataset({cvar:ds_cvar})\n",
    "    ds_fine.coords['lat'] = latmesh\n",
    "    ds_fine.coords['lon'] = lonmesh\n",
    "    ds_fine.coords['y'] = y_arr\n",
    "    ds_fine.coords['x'] = x_arr\n",
    "    #\n",
    "    ds_fine.coords['lat_b'] = latmesh_b\n",
    "    ds_fine.coords['lon_b'] = lonmesh_b\n",
    "    ds_fine.coords['y_b'] = y_arr_b\n",
    "    ds_fine.coords['x_b'] = x_arr_b\n",
    "\n",
    "    ds_fine.coords['lat_f'] = xr.DataArray(lat_arr, dims=('y'))\n",
    "    ds_fine.coords['lon_f'] = xr.DataArray(lon_arr, dims=('x'))\n",
    "\n",
    "    ds_fine['counter'] = xr.DataArray(np.ones((len(lat_arr),len(lon_arr))), dims=('y','x'))\n",
    "    \n",
    "    # Add point data to fine grid\n",
    "    print(\"Found\",X2.point.size,\"points.\")\n",
    "    print(\"Adding to fine grid...\")\n",
    "    start_time_cmod = timeit.default_timer()\n",
    "\n",
    "    # Get locations of all points in ds_fine grid\n",
    "    X_points = ds_fine.swap_dims({'x':'lon_f','y':'lat_f'}).sel(lat_f=X2.lat, lon_f=X2.lon, method='nearest')\n",
    "\n",
    "    # Loop through points and add up on fine grid\n",
    "    for pt in X_points.point:\n",
    "\n",
    "        # Set that value\n",
    "        if ds_fine[cvar][pt.y,pt.x].isnull(): # Set if nan\n",
    "            ds_fine[cvar][pt.y,pt.x] = X2.sel(point=pt)#.values\n",
    "        else:\n",
    "            # add them\n",
    "            ds_fine[cvar][pt.y,pt.x] = ds_fine[cvar][pt.y,pt.x] + X2.sel(point=pt)#.values\n",
    "            # increment counter \n",
    "            ds_fine['counter'][pt.y,pt.x] = ds_fine['counter'][pt.y,pt.x] + 1 \n",
    "    print(\"Took \", (timeit.default_timer() - start_time_cmod)/X2.point.size, \" seconds / point.\")\n",
    "\n",
    "    # Divide\n",
    "    ds_fine[cvar] = ds_fine[cvar] / ds_fine['counter']\n",
    "    ds_fine = ds_fine.drop('counter')\n",
    "    ds_fine['mask'] = ds_fine.hi.notnull()\n",
    "    \n",
    "\n",
    "    # Check ds_fine still contains some non-NaN data\n",
    "    if ds_fine[cvar].notnull().sum()==0:\n",
    "        raise ValueError(\"No data left in ds_fine!\")\n",
    "    \n",
    "    # Regrid\n",
    "    regridder = xe.Regridder(ds_fine, obs_grid, method, periodic=False, \n",
    "                             reuse_weights='False')\n",
    "    offset = 10\n",
    "    ds_coarse = regridder(ds_fine[cvar]+10)\n",
    "    ds_coarse = ds_coarse.where(ds_coarse>=(offset)) - offset\n",
    "    regridder.clean_weight_file()\n",
    "    \n",
    "    # Add info\n",
    "    ds_coarse.coords['time'] = cdate\n",
    "    \n",
    "    # Save to file\n",
    "    ds_coarse.to_netcdf(f_o)\n",
    "    print(\"Saved\",f_o)\n",
    "    \n",
    "    if test_plots:\n",
    "        plt.figure()\n",
    "        X2.plot.hist(bins=100, color='k', alpha=0.3, label='Point Raw');\n",
    "        ds_fine[cvar].plot.hist(bins=100, color='r', alpha=0.3, label='1km gridded mean');\n",
    "        ds_coarse.plot.hist(bins=100, color='g', alpha=0.3, label='25km gridded mean');\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(X2.point,X2)\n",
    "\n",
    "        plt.figure()\n",
    "        f = plt.figure(figsize=(10, 10))\n",
    "        ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=-45))\n",
    "        ax.coastlines(linewidth=0.75, color='black', resolution='50m')\n",
    "        plt.scatter(X2.lon, X2.lat, c=X2,transform=ccrs.PlateCarree())\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.figure()\n",
    "        f = plt.figure(figsize=(10, 10))\n",
    "        ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=-45))\n",
    "        ax.coastlines(linewidth=0.75, color='black', resolution='50m')\n",
    "        ds_fine[cvar].plot(x='lon',y='lat',transform=ccrs.PlateCarree())\n",
    "\n",
    "        plt.figure()\n",
    "        f = plt.figure(figsize=(10, 10))\n",
    "        ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=-45))\n",
    "        ax.coastlines(linewidth=0.75, color='black', resolution='50m')\n",
    "        ds_coarse.plot(x='lon',y='lat',transform=ccrs.PlateCarree())\n",
    "        ax.set_extent([ds_fine.lon.min().values,\n",
    "                      ds_fine.lon.max().values,\n",
    "                      ds_fine.lat.min().values,\n",
    "                      ds_fine.lat.max().values])\n",
    "\n",
    "    #xr.exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Going from point to fine grid\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # Check lat/lon bounds\n",
    "# # f = plt.figure(figsize=(10, 10))\n",
    "# # ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# # ax.coastlines(linewidth=0.75, color='black', resolution='50m')\n",
    "# # ax.scatter(ds_fine.lon[0:10,0:10],ds_fine.lat[0:10,0:10],color='k', transform=ccrs.PlateCarree())\n",
    "# # ax.scatter(ds_fine.lon_b[0:10,0:10],ds_fine.lat_b[0:10,0:10],color='r', transform=ccrs.PlateCarree())\n",
    "\n",
    "# # # ax.scatter(ds_fine.lon[0:100:ds_fine.lon.size].values,\n",
    "# # #            ds_fine.lat[0:100:ds_fine.lat.size].values,color='k', \n",
    "# # #            transform=ccrs.PlateCarree())\n",
    "\n",
    "# # # Compare target and source grids\n",
    "# # # Check lat/lon bounds\n",
    "# # f = plt.figure(figsize=(10, 10))\n",
    "# # ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=-45))\n",
    "# # ax.coastlines(linewidth=0.75, color='black', resolution='50m')\n",
    "# # ax.scatter(ds_fine.lon,ds_fine.lat,color='k',marker='.', transform=ccrs.PlateCarree())\n",
    "# # ax.scatter(obs_grid.lon,obs_grid.lat,color='r', transform=ccrs.PlateCarree())\n",
    "# # ax.scatter(ds_fine.lon,ds_fine.lat,color='k',marker='.', transform=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # Save to bucket\n",
    "\n",
    "# # ds_fine.to_netcdf('/home/disk/sipn/nicway/data/temp/IBdata/ds_fine.nc')\n",
    "# # obs_grid.to_netcdf('/home/disk/sipn/nicway/data/temp/IBdata/ds_target.nc')\n",
    "\n",
    "# # ds_fine.to_zarr('/home/disk/sipn/nicway/data/temp/IBdata/fine.zarr', mode='w')\n",
    "# # obs_grid.to_zarr('/home/disk/sipn/nicway/data/temp/IBdata/target.zarr', mode='w')\n",
    "\n",
    "# ds_fine.hi.plot.hist(bins=100);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# f = plt.figure(figsize=(10, 10))\n",
    "# ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=-45))\n",
    "# ax.coastlines(linewidth=0.75, color='black', resolution='50m')\n",
    "# ds_fine[cvar].plot(x='lon',y='lat',transform=ccrs.PlateCarree(),vmin=0,vmax=1)\n",
    "\n",
    "# f = plt.figure(figsize=(10, 10))\n",
    "# ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=-45))\n",
    "# ax.coastlines(linewidth=0.75, color='black', resolution='50m')\n",
    "# #ax.gridlines(crs=ccrs.PlateCarree(), linestyle='-')\n",
    "# ds_coarse.plot(x='lon',y='lat',transform=ccrs.PlateCarree(),vmin=0,vmax=1)\n",
    "# #ds_fine[cvar].plot(x='lon',y='lat',transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "\n",
    "# ax.set_extent([ds_fine.lon.min().values,\n",
    "#                ds_fine.lon.max().values,\n",
    "#                ds_fine.lat.min().values,\n",
    "#                ds_fine.lat.max().values])\n",
    "# # ax.scatter(ds_fine.lon[0:100:ds_fine.lon.size].values,\n",
    "# #            ds_fine.lat[0:100:ds_fine.lat.size].values,color='k', \n",
    "# #            transform=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xr.exit()\n",
    "\n",
    "\n",
    "\n",
    "# # LAT_STR = 'lat'\n",
    "# # LON_STR = 'lon'\n",
    "# # LAT_BOUNDS_STR = 'lat_b'\n",
    "# # LON_BOUNDS_STR = 'lon_b'\n",
    "# # X_STR = 'x'\n",
    "# # Y_STR = 'y'\n",
    "# # X_BOUNDS_STR = 'x_b'\n",
    "# # Y_BOUNDS_STR = 'y_b'\n",
    "\n",
    "\n",
    "# # def add_lat_lon_bounds(arr, lat_str=LAT_STR, lon_str=LON_STR,\n",
    "# #                        lat_bounds_str=LAT_BOUNDS_STR,\n",
    "# #                        lon_bounds_str=LON_BOUNDS_STR,\n",
    "# #                        lat_min=-90., lat_max=90.,\n",
    "# #                        lon_min=0., lon_max=360.):\n",
    "# #     \"\"\"Add bounding arrays to lat and lon arrays.\"\"\"\n",
    "# #     lon_vals = arr[lon_str].values\n",
    "# #     lon_bounds_values = 0.5*(lon_vals[:-1] + lon_vals[1:])\n",
    "# #     lon_bounds = np.concatenate([[lon_min], lon_bounds_values, [lon_max]])\n",
    "    \n",
    "# #     lat_vals = arr[lat_str].values\n",
    "# #     lat_bounds_values = 0.5*(lat_vals[:-1] + lat_vals[1:])\n",
    "# #     lat_bounds = np.concatenate([[lat_min], lat_bounds_values, [lat_max]])\n",
    "    \n",
    "# #     ds = arr.to_dataset()\n",
    "# #     ds.coords[lon_bounds_str] = xr.DataArray(lon_bounds, dims=[X_BOUNDS_STR])\n",
    "# #     ds.coords[lat_bounds_str] = xr.DataArray(lat_bounds, dims=[Y_BOUNDS_STR])\n",
    "    \n",
    "# #     return ds\n",
    "\n",
    "# # ds_fine_4_xesmf_bnds = add_lat_lon_bounds(ds_fine[cvar], \n",
    "# #                        lat_str=LAT_STR, lon_str=LON_STR,\n",
    "# #                        lat_bounds_str=LAT_BOUNDS_STR,\n",
    "# #                        lon_bounds_str=LON_BOUNDS_STR,\n",
    "# #                        lat_min=ds_fine.lat.min().values, \n",
    "# #                        lat_max=ds_fine.lat.max().values, \n",
    "# #                        lon_min=ds_fine.lon.min().values, \n",
    "# #                        lon_max=ds_fine.lon.min().values)\n",
    "# # ds_fine_4_xesmf_bnds                       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ds_fine.hi.plot.hist(alpha=0.5,label='gridded');\n",
    "# X2.plot.hist(alpha=0.5,label='point data')\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "# f = plt.figure(figsize=(10, 10))\n",
    "# ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# ax.coastlines(linewidth=0.75, color='black', resolution='50m')\n",
    "# #ax.gridlines(crs=ccrs.PlateCarree(), linestyle='-')\n",
    "# ax.scatter(ds_fine_lon[0:3893:100, 0:14527:100].values,\n",
    "#            ds_fine_lat[0:3893:100, 0:14527:100].values,color='k', \n",
    "#            transform=ccrs.PlateCarree())\n",
    "# plt.plot(X2.lon,X2.lat,'r*')\n",
    "\n",
    "# # First grid point data\n",
    "\n",
    "# import collocate\n",
    "\n",
    "# pt_lat = obs_grid.stack(gridcell=('ni', 'nj')).rename({'lat':'latitude','lon':'longitude'}).latitude\n",
    "# pt_lon = obs_grid.stack(gridcell=('ni', 'nj')).rename({'lat':'latitude','lon':'longitude'}).longitude\n",
    "\n",
    "# da_pt = xr.DataArray(np.zeros(pt_lat.size), dims=('gridcell'), coords = {'latitude':pt_lat, 'longitude':pt_lon})\n",
    "# da_pt\n",
    "\n",
    "# ds_fine\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ds_IN.hi.to_dataframe('var')\n",
    "\n",
    "# ds_IN = ds_fine.rename({'lat':'latitude','lon':'longitude'}).swap_dims({'latitude':'lat_i','longitude':'lon_i'})\n",
    "\n",
    "# # (Points, grid, distance)\n",
    "# IB_mean = collocate.collocate(da_pt, \n",
    "#                               ds_IN,\n",
    "#                               h_sep=25)\n",
    "\n",
    "# IB_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xr.exit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ds_all.where(ds_all.hi.notnull(), drop=True).date.plot()\n",
    "\n",
    "# ## Test plots below\n",
    "# # Get sea ice thickness data\n",
    "\n",
    "\n",
    "# # ds_all = xr.open_mfdataset(nc_dir+'/*.nc', concat_dim='point')\n",
    "\n",
    "# # Due to file name change, point is not in time order\n",
    "# ds_all.date.plot()\n",
    "\n",
    "# ds_all.hi.mean().values\n",
    "\n",
    "# ds_all.hi.plot.hist(bins=100);\n",
    "\n",
    "# ds_all.sd.plot.hist(bins=100);\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# ds_all.hi.plot(color='k')\n",
    "\n",
    "# ds_all.date.plot()\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.plot(ds_all.hi.values, ds_all.date.values,'k*')\n",
    "\n",
    "# (f, ax) = ice_plot.polar_axis()\n",
    "# f.set_size_inches(20,10)\n",
    "# plt.scatter(ds_all.lon.values, ds_all.lat.values, transform=ccrs.PlateCarree(), c='r', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.4 esio",
   "language": "python",
   "name": "esio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
