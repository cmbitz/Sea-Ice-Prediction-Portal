{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This code is part of the SIPN2 project focused on improving sub-seasonal to seasonal predictions of Arctic Sea Ice. \n",
    "If you use this code for a publication or presentation, please cite the reference in the README.md on the\n",
    "main page (https://github.com/NicWayand/ESIO). \n",
    "\n",
    "Questions or comments should be addressed to nicway@uw.edu\n",
    "\n",
    "Copyright (c) 2018 Nic Wayand\n",
    "\n",
    "GNU General Public License v3.0\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "Collect the weekly metrics into zarr file for cloud upload\n",
    "redoes last two months worth each time\n",
    "includes observations so may wish to go back deeper in time\n",
    "for ease of verification. looks like we have an additional\n",
    "zarr of observations though and obs here are not used in the map plots anyway\n",
    "'''\n",
    "\n",
    "#%matplotlib inline\n",
    "#%load_ext autoreload\n",
    "#%autoreload\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import struct\n",
    "import os\n",
    "import xarray as xr\n",
    "import glob\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import seaborn as sns\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning) # not good to supress but they divide by nan are annoying\n",
    "#warnings.simplefilter(action='ignore', category=UserWarning) # https://github.com/pydata/xarray/issues/2273\n",
    "import json\n",
    "from esio import EsioData as ed\n",
    "from esio import ice_plot\n",
    "from esio import import_data\n",
    "import subprocess\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x14b900d69cf8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(scheduler='threads')  # overwrite default with threaded scheduler (This is faster for this code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "# client = Client(n_workers=8)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-07T00:00:00.000000000 2019-11-24T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "#def Update_PanArctic_Maps():\n",
    "# Plotting Info\n",
    "runType = 'forecast'\n",
    "variables = ['sic']\n",
    "metrics_all = {'sic':['anomaly','mean','SIP'], 'hi':['mean']}\n",
    "#metrics_all = {'sic':['SIP']}\n",
    "\n",
    "# Define Init Periods here, spaced by 7 days (aprox a week)\n",
    "# Now\n",
    "cd = datetime.datetime.now()\n",
    "cd = datetime.datetime(cd.year, cd.month, cd.day) # Set hour min sec to 0. \n",
    "# Hardcoded start date (makes incremental weeks always the same)\n",
    "start_t = datetime.datetime(1950, 1, 1) # datetime.datetime(1950, 1, 1)\n",
    "# Params for this plot\n",
    "Ndays = 7 # time period to aggregate maps to (default is 7)\n",
    "Npers = 4 # init periods to put into a Zarr chunk\n",
    "\n",
    "init_start_date = np.datetime64('2018-01-01')\n",
    "updateAll = False  # may wish to update all up to a year in the past to get observations\n",
    "                   # for verification in the maps\n",
    "                   # must first run Calc_Weekly_Model_Metrics to update Obs\n",
    "                   # though that script supposedly does update obs each time \n",
    "\n",
    "#init_start_date = np.datetime64('2019-01-01')\n",
    "#updateAll = True\n",
    "\n",
    "\n",
    "init_slice = np.arange(start_t, cd, datetime.timedelta(days=Ndays)).astype('datetime64[ns]')\n",
    "# init_slice = init_slice[-Npers:] # Select only the last Npers of periods (weeks) since current date\n",
    "init_slice = init_slice[init_slice>=init_start_date] # Select only the inits after init_start_date\n",
    "print(init_slice[0],init_slice[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(init_slice[72:])\n",
    "#updateAll=True\n",
    "#init_slice=init_slice[92:93]\n",
    "#print(init_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Load in Observed and non-dynamic model Data\n",
    "#############################################################\n",
    "\n",
    "E = ed.EsioData.load()\n",
    "mod_dir = E.model_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_slice=init_slice[80:]\n",
    "#init_slice=init_slice[72:]\n",
    "#updateAll=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking on  2019-07-21T00:00:00.000000000\n",
      "Processing 2019-07-21T00:00:00.000000000 2019-08-11T00:00:00.000000000\n",
      "Loading in weekly metrics...\n",
      "    Loading anomaly ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 14\n",
      "  **atop_kwargs)\n",
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loading mean ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 14\n",
      "  **atop_kwargs)\n",
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loading SIP ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 14\n",
      "  **atop_kwargs)\n",
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to Zarr...\n",
      "Finished  2019-07-21\n",
      "Took  23.960748594696632  minutes.\n",
      "Checking on  2019-08-18T00:00:00.000000000\n",
      "Processing 2019-08-18T00:00:00.000000000 2019-09-08T00:00:00.000000000\n",
      "Loading in weekly metrics...\n",
      "    Loading anomaly ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 16\n",
      "  **atop_kwargs)\n",
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n",
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 17\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loading mean ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 16\n",
      "  **atop_kwargs)\n",
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n",
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 17\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loading SIP ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 16\n",
      "  **atop_kwargs)\n",
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n",
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 17\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to Zarr...\n",
      "Finished  2019-08-18\n",
      "Took  5.399449451888601  minutes.\n",
      "Checking on  2019-09-15T00:00:00.000000000\n",
      "Processing 2019-09-15T00:00:00.000000000 2019-10-06T00:00:00.000000000\n",
      "Loading in weekly metrics...\n",
      "    Loading anomaly ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loading mean ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loading SIP ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to Zarr...\n",
      "Finished  2019-09-15\n",
      "Took  5.110456004731047  minutes.\n",
      "Checking on  2019-10-13T00:00:00.000000000\n",
      "Processing 2019-10-13T00:00:00.000000000 2019-11-03T00:00:00.000000000\n",
      "Loading in weekly metrics...\n",
      "    Loading anomaly ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loading mean ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loading SIP ...\n",
      "    Found 100 initialization periods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/array/core.py:3233: PerformanceWarning: Increasing number of chunks by factor of 15\n",
      "  **atop_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to Zarr...\n",
      "Finished  2019-10-13\n",
      "Took  4.512721475493163  minutes.\n",
      "Checking on  2019-11-10T00:00:00.000000000\n",
      "Processing 2019-11-10T00:00:00.000000000 2019-11-24T00:00:00.000000000\n",
      "Loading in weekly metrics...\n",
      "    Loading anomaly ...\n",
      "    Found 100 initialization periods.\n",
      "    Loading mean ...\n",
      "    Found 100 initialization periods.\n",
      "    Loading SIP ...\n",
      "    Found 100 initialization periods.\n",
      "Saving to Zarr...\n",
      "Finished  2019-11-10\n",
      "Took  2.641854993882589  minutes.\n"
     ]
    }
   ],
   "source": [
    "#from esio import import_data_CCtest   # added some extra print statements for helping diagnose\n",
    "\n",
    "cvar = 'sic' # hard coded for now\n",
    "\n",
    "# do not read in any files for these models\n",
    "leave_out = ['noaasipn','modcansipns_3','modcansipns_4','ecmwfc','kmac','ukmoc','metreofrc','ncepc']\n",
    "\n",
    "# For each init chunk\n",
    "for IS in np.arange(0,len(init_slice),Npers): # Every fourth init date\n",
    "    start_time_cmod = timeit.default_timer()\n",
    "\n",
    "    it_start = init_slice[IS]\n",
    "    if (IS+Npers-1)>=len(init_slice):\n",
    "        it_end = init_slice[-1]\n",
    "    else:\n",
    "        it_end = init_slice[IS+Npers-1]\n",
    "    \n",
    "    # Output Zarr dir\n",
    "    c_zarr_file = os.path.join(E.data_dir,'model/zarr', 'temp', cvar+pd.to_datetime(it_start).strftime('_%Y-%m-%d')+'.zarr')\n",
    "    \n",
    "    print(\"Checking on \",it_start)\n",
    "    \n",
    "    # Check if dir exists\n",
    "    if updateAll | (os.path.isdir(c_zarr_file)==False) | (it_start>init_slice[-6] - np.timedelta64(60,'D')):\n",
    "#    if updateAll | (os.path.isdir(c_zarr_file)==False) | (it_start>=init_slice[52]):\n",
    "\n",
    "        print(\"Processing\",it_start, it_end)\n",
    "\n",
    "        # Load in all metrics for given variable\n",
    "        print(\"Loading in weekly metrics...\")\n",
    "        ds_m = import_data.load_MME_by_init_end(E=E, \n",
    "#        ds_m = import_data_CCtest.load_MME_by_init_end(E=E, \n",
    "                                                runType=runType, \n",
    "                                                variable=cvar, \n",
    "                                                metrics=metrics_all[cvar],\n",
    "                                                init_range=[it_start,it_end],\n",
    "                                                leave_out = leave_out)\n",
    "    \n",
    "        # Get list of dynamical models that are not observations\n",
    "        dynamical_Models = [x for x in ds_m.model.values if x not in ['Observed','climatology','climo10yrs','dampedAnomalyTrend']]\n",
    "        # # Get list of all models\n",
    "        # all_Models = [x for x in ds_m.model.values if x not in ['Observed']]\n",
    "        # Add MME\n",
    "        MME_avg = ds_m.sel(model=dynamical_Models).mean(dim='model') # only take mean over dynamical models\n",
    "        MME_avg.coords['model'] = 'MME'\n",
    "        ds_ALL = xr.concat([ds_m, MME_avg], dim='model')\n",
    "\n",
    "        ####################################\n",
    "#         print(ds_ALL)\n",
    "\n",
    "\n",
    "        # Rechunk from ~1MB to 100MB chunks\n",
    "        # Chunk along fore_time and init_end\n",
    "        ds_ALL = ds_ALL.chunk({'init_end':10,'fore_time': 10, 'model': 1, 'x': 304, 'y': 448})\n",
    "\n",
    "        # Save to Zarr chunk\n",
    "        print(\"Saving to Zarr...\")\n",
    "        ds_ALL.to_zarr(c_zarr_file, mode='w')\n",
    "        print(\"Finished \",pd.to_datetime(it_start).strftime('%Y-%m-%d'))\n",
    "        print(\"Took \", (timeit.default_timer() - start_time_cmod)/60, \" minutes.\")\n",
    "        ds_ALL=None # Flush memory\n",
    "        MME_avg=None\n",
    "        ds_m=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xr.open_zarr('/home/disk/sipn/nicway/data/model/zarr/temp/sic_2018-06-24.zarr').SIP.sel(model='MME').notnull().sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sic_2018-01-07.zarr',\n",
       " 'sic_2018-02-04.zarr',\n",
       " 'sic_2018-03-04.zarr',\n",
       " 'sic_2018-04-01.zarr',\n",
       " 'sic_2018-04-29.zarr',\n",
       " 'sic_2018-05-27.zarr',\n",
       " 'sic_2018-06-24.zarr',\n",
       " 'sic_2018-07-22.zarr',\n",
       " 'sic_2018-08-19.zarr',\n",
       " 'sic_2018-09-16.zarr',\n",
       " 'sic_2018-10-14.zarr',\n",
       " 'sic_2018-11-11.zarr',\n",
       " 'sic_2018-12-09.zarr',\n",
       " 'sic_2019-01-06.zarr',\n",
       " 'sic_2019-02-03.zarr',\n",
       " 'sic_2019-03-03.zarr',\n",
       " 'sic_2019-03-31.zarr',\n",
       " 'sic_2019-04-28.zarr',\n",
       " 'sic_2019-05-26.zarr',\n",
       " 'sic_2019-06-23.zarr',\n",
       " 'sic_2019-07-21.zarr',\n",
       " 'sic_2019-08-18.zarr',\n",
       " 'sic_2019-09-15.zarr',\n",
       " 'sic_2019-10-13.zarr',\n",
       " 'sic_2019-11-10.zarr']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all Zarr chunks\n",
    "zarr_dir = '/home/disk/sipn/nicway/data/model/zarr/temp/'\n",
    "zarr_inits = sorted([ name for name in os.listdir(zarr_dir) if os.path.isdir(os.path.join(zarr_dir, name)) ])\n",
    "zarr_inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "zl = []\n",
    "for c_init in zarr_inits:\n",
    "    ds = xr.open_zarr(os.path.join(zarr_dir,c_init))\n",
    "    zl.append(ds)\n",
    "ds_Zarr = xr.concat(zl,dim='init_end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (fore_time: 52, init_end: 99, model: 23, x: 304, y: 448)\n",
      "Coordinates:\n",
      "  * model      (model) object 'MME' 'Observed' 'awispin' ... 'usnavysipn' 'yopp'\n",
      "  * fore_time  (fore_time) timedelta64[ns] 0 days 7 days ... 350 days 357 days\n",
      "    lat        (x, y) float64 31.1 31.25 31.4 31.55 ... 34.92 34.77 34.62 34.47\n",
      "    lon        (x, y) float64 168.3 168.4 168.5 168.7 ... -9.745 -9.872 -9.999\n",
      "  * x          (x) int64 0 1 2 3 4 5 6 7 8 ... 296 297 298 299 300 301 302 303\n",
      "  * y          (y) int64 0 1 2 3 4 5 6 7 8 ... 440 441 442 443 444 445 446 447\n",
      "  * init_end   (init_end) datetime64[ns] 2018-01-07 2018-01-14 ... 2019-11-24\n",
      "Data variables:\n",
      "    SIP        (init_end, model, fore_time, y, x) float64 dask.array<shape=(99, 23, 52, 448, 304), chunksize=(4, 1, 10, 448, 304)>\n",
      "    anomaly    (init_end, model, fore_time, y, x) float64 dask.array<shape=(99, 23, 52, 448, 304), chunksize=(4, 1, 10, 448, 304)>\n",
      "    mean       (init_end, model, fore_time, y, x) float64 dask.array<shape=(99, 23, 52, 448, 304), chunksize=(4, 1, 10, 448, 304)>\n"
     ]
    }
   ],
   "source": [
    "print(ds_Zarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ADD METADATA #################\n",
    "\n",
    "## Add coordinate system info\n",
    "ds_Zarr.coords['crs'] = xr.DataArray('crs')\n",
    "ds_Zarr['crs'].attrs = {\n",
    "    'comment': '(https://nsidc.org/data/polar-stereo/ps_grids.html or https://nsidc.org/data/oib/epsg_3413.html) This is a container variable that describes the grid_mapping used by the data in this file. This variable does not contain any data; only information about the geographic coordinate system',\n",
    "    'grid_mapping_name': 'polar_stereographic',\n",
    "    'straight_vertical_longitude_from_pole':'-45',\n",
    "    'latitude_of_projection_origin': '90.0',\n",
    "    'standard_parallel':'70',\n",
    "    'false_easting':'0',\n",
    "    'false_northing':'0'\n",
    "    }\n",
    "\n",
    "# Add time coords\n",
    "ds_Zarr.coords['init_start'] = ds_Zarr.init_end - np.timedelta64(Ndays,'D') + np.timedelta64(1,'D')\n",
    "ds_Zarr['init_start'].attrs = {\n",
    "    'comment':        'Start date for weekly average period',\n",
    "    'long_name':      'Start date for weekly average period',\n",
    "    'standard_name':  \"start_init_date\"}\n",
    "\n",
    "ds_Zarr['init_end'].attrs = {\n",
    "    'comment':        'End date for weekly average period',\n",
    "    'long_name':      'End date for weekly average period',\n",
    "    'standard_name':  \"end_init_date\"}\n",
    "\n",
    "ds_Zarr['fore_time'].attrs = {\n",
    "    'comment':        'Forecast lead time',\n",
    "    'long_name':      'Forecast lead time',\n",
    "    'standard_name':  \"forecast_lead_time\"}\n",
    "\n",
    "# Add Valid time (start and end period)\n",
    "ds_Zarr = import_data.get_valid_time(ds_Zarr, init_dim='init_end', fore_dim='fore_time')\n",
    "ds_Zarr.rename({'valid_time':'valid_end'}, inplace=True);\n",
    "ds_Zarr.coords['valid_start'] = ds_Zarr.valid_end - np.timedelta64(Ndays,'D') + np.timedelta64(1,'D')\n",
    "\n",
    "# Add attributes\n",
    "ds_Zarr['valid_end'].attrs = {\n",
    "    'comment':        'End Valid date for weekly average period',\n",
    "    'long_name':      'End Valid date for weekly average period',\n",
    "    'standard_name':  \"end_valid_date\"}\n",
    "\n",
    "ds_Zarr['valid_start'].attrs = {\n",
    "    'comment':        'Start Valid date for weekly average period',\n",
    "    'long_name':      'Start Valid date for weekly average period',\n",
    "    'standard_name':  \"start_valid_date\"}\n",
    "\n",
    "# Add Variable attributes\n",
    "ds_Zarr['SIP'].attrs = {\n",
    "    'comment':        'Sea ice probability, calculated by averaging across ensemble members predictions of sea ice concentration >= 0.15',\n",
    "    'grid_mapping':   'crs',\n",
    "    'long_name':      'Sea ice probability',\n",
    "    'standard_name':  \"sea_ice_probability\",\n",
    "    'units':          'fraction'}\n",
    "\n",
    "ds_Zarr['anomaly'].attrs = {\n",
    "    'comment':        'Anomaly of the forecasted sea ice concentration mean (ensemble average) compared to the 1980 to 2010 Observed Climatology',\n",
    "    'grid_mapping':   'crs',\n",
    "    'long_name':      'Anomaly',\n",
    "    'standard_name':  \"anomaly\",\n",
    "    'units':          'fraction'}\n",
    "\n",
    "ds_Zarr['mean'].attrs = {\n",
    "    'comment':        'Mean of the forecasted sea ice concentration (ensemble average)',\n",
    "    'grid_mapping':   'crs',\n",
    "    'long_name':      'Sea ice concentration',\n",
    "    'standard_name':  \"sea_ice_concentration\",\n",
    "    'units':          'fraction'}\n",
    "\n",
    "# Dataset Attributes\n",
    "ds_Zarr.attrs = {\n",
    "'comment':                         'Weekly mean sea ice concentration forecasted by multiple models as well as observed by remotly sensed passive microwave sensors.',\n",
    "'contact':                         'nicway@uw.edu',\n",
    "'creator_email':                   'nicway@uw.edu',\n",
    "'creator_name':                    'Nicholas Wayand, University of Washington',\n",
    "'creator_url':                     'https://atmos.uw.edu/sipn/',\n",
    "'date_created':                    '2018-12-03T00:00:00',\n",
    "'date_modified':                   datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "'geospatial_lat_max':              str(float(ds_Zarr.lat.max().values)),\n",
    "'geospatial_lat_min':              str(float(ds_Zarr.lat.min().values)),\n",
    "'geospatial_lat_resolution':       '~25km',\n",
    "'geospatial_lat_units':            'degrees_north',\n",
    "'geospatial_lon_max':              str(float(ds_Zarr.lon.max().values)),\n",
    "'geospatial_lon_min':              str(float(ds_Zarr.lon.min().values)),\n",
    "'geospatial_lon_resolution':       '~25km',\n",
    "'geospatial_lon_units':            'degrees_east',\n",
    "'history':                         datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')+': updated by Nicholas Wayand',\n",
    "'institution':                     'UW, SIPN, ARCUS',\n",
    "'keywords':                        'Arctic > Sea ice concentration > Prediction',\n",
    "'product_version':                 '1.0',\n",
    "'project':                         'Sea Ice Prediction Network Phase II',\n",
    "'references':                      'Wayand, N.E., Bitz, C.M., and E. Blanchard-Wrigglesworth, (in review). A year-round sub-seasonal to seasonal sea ice prediction portal. Submited to Geophysical Research letters.',\n",
    "'source':                          'Numerical model predictions and Passive microwave measurments.',\n",
    "'summary':                         'Dataset is updated daily with weekly sea ice forecasts',\n",
    "'time_coverage_end':               pd.to_datetime(ds_Zarr.valid_end.max().values).strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "'time_coverage_start':             pd.to_datetime(ds_Zarr.init_start.min().values).strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "'title':                           'SIPN2 Sea ice Concentration Forecasts and Observations.'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to decode strings\n",
    "# ds_Zarr['model'] = [s.decode(\"utf-8\") for s in ds_Zarr.model.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to Large Zarr.\n"
     ]
    }
   ],
   "source": [
    "# Save to one Big Zarr\n",
    "ds_Zarr.to_zarr(os.path.join(E.data_dir,'model/zarr', cvar+'.zarr'), mode='w')\n",
    "print(\"Saved to Large Zarr.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/data/model/zarr/sic.zarr\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(E.data_dir,'model/zarr', cvar+'.zarr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
