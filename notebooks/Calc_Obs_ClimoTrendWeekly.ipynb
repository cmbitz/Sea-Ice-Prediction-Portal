{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "This code is part of the SIPN2 project focused on improving sub-seasonal to seasonal predictions of Arctic Sea Ice. \n",
    "If you use this code for a publication or presentation, please cite the reference in the README.md on the\n",
    "main page (https://github.com/NicWayand/ESIO). \n",
    "\n",
    "Questions or comments should be addressed to nicway@uw.edu\n",
    "\n",
    "Copyright (c) 2018 Nic Wayand\n",
    "\n",
    "GNU General Public License v3.0\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "For the bootstrap and latest nrt weekly mean obs since 1990 (it was made weekly in Agg_NSIDC_Obs)\n",
    "filter with a LOESS smoother in time then polynomial fit to get the \n",
    "fit parameters. Save the fit parameters since this takes forever.\n",
    "\n",
    "Later read in fit parameters to extrapolate forward, giving climatological trend \n",
    "benchmark\n",
    "\n",
    "Also use fit parameters for each year to compute an anomaly and save that too for computing alpha\n",
    "\n",
    "At present this routine is meant to be used once a year, but should make it so that it produces a new climotrend\n",
    "estimate each week!!!\n",
    "\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import struct\n",
    "import os\n",
    "import xarray as xr\n",
    "import glob\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import seaborn as sns\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from esio import EsioData as ed\n",
    "from esio import ice_plot\n",
    "from esio import import_data\n",
    "from esio import metrics\n",
    "import dask\n",
    "\n",
    "# General plotting settings\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context(\"talk\", font_scale=.8, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x150d330fd550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dask.distributed import Client\n",
    "# client = Client(n_workers=2)\n",
    "# client = Client()\n",
    "# client\n",
    "dask.config.set(scheduler='threads')  # overwrite default with threaded scheduler\n",
    "# dask.config.set(scheduler='processes')  # overwrite default with threaded scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "today_date = datetime.datetime.now()\n",
    "pred_year = today_date.year + 1\n",
    "print(pred_year)  # normally we are computing the fits for predicting far into the future\n",
    "#pred_year = 2020 # can force to do a particular year but 2018 and 2019 are done already\n",
    "start_year = 1990\n",
    "E = ed.EsioData.load()\n",
    "mod_dir = E.model_dir\n",
    "cmod = 'climatology'\n",
    "runType = 'forecast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'sic' (time: 228, y: 448, x: 304)>\n",
      "dask.array<shape=(228, 448, 304), dtype=float64, chunksize=(52, 448, 304)>\n",
      "Coordinates:\n",
      "  * x        (x) int64 0 1 2 3 4 5 6 7 8 ... 295 296 297 298 299 300 301 302 303\n",
      "  * y        (y) int64 0 1 2 3 4 5 6 7 8 ... 439 440 441 442 443 444 445 446 447\n",
      "    lat      (x, y) float64 31.1 31.25 31.4 31.55 ... 34.92 34.77 34.62 34.47\n",
      "    lon      (x, y) float64 168.3 168.4 168.5 168.7 ... -9.745 -9.872 -9.999\n",
      "    xm       (x) int64 -3850000 -3825000 -3800000 ... 3675000 3700000 3725000\n",
      "    ym       (y) int64 5850000 5825000 5800000 ... -5275000 -5300000 -5325000\n",
      "  * time     (time) datetime64[ns] 2015-01-07 2015-01-14 ... 2019-05-20\n",
      "    week     (time) int64 dask.array<shape=(228,), chunksize=(52,)>\n",
      "<xarray.DataArray 'sic' (time: 1508, y: 448, x: 304)>\n",
      "dask.array<shape=(1508, 448, 304), dtype=float64, chunksize=(52, 448, 304)>\n",
      "Coordinates:\n",
      "  * x        (x) int64 0 1 2 3 4 5 6 7 8 ... 295 296 297 298 299 300 301 302 303\n",
      "  * y        (y) int64 0 1 2 3 4 5 6 7 8 ... 439 440 441 442 443 444 445 446 447\n",
      "    lat      (x, y) float64 31.1 31.25 31.4 31.55 ... 34.92 34.77 34.62 34.47\n",
      "    lon      (x, y) float64 168.3 168.4 168.5 168.7 ... -9.745 -9.872 -9.999\n",
      "    xm       (x) int64 -3850000 -3825000 -3800000 ... 3675000 3700000 3725000\n",
      "    ym       (y) int64 5850000 5825000 5800000 ... -5275000 -5300000 -5325000\n",
      "  * time     (time) datetime64[ns] 1990-01-07 1990-01-14 ... 2018-12-30\n",
      "    week     (time) int64 dask.array<shape=(1508,), chunksize=(52,)>\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Load in Data that have already been averaged for each week of the year, always starting on Jan 1\n",
    "#############################################################\n",
    "\n",
    "# BE SURE THESE ARE NON OVERLAPPING, MUST BE UPDATED FOR NEW DATA\n",
    "# Get bootstrap and nrt observations with pole hole already filled in\n",
    "ds_81 = xr.open_mfdataset(E.obs['NSIDC_0081']['sipn_nc']+'_yearly_byweek/*byweek.nc', concat_dim='time', autoclose=True, parallel=True).sic\n",
    "#ds_51 = xr.open_mfdataset(E.obs['NSIDC_0051']['sipn_nc']+'_yearly_byweek/*byweek.nc', concat_dim='time', autoclose=True, parallel=True)\n",
    "ds_79 = xr.open_mfdataset(E.obs['NSIDC_0079']['sipn_nc']+'_yearly_byweek/*byweek.nc', concat_dim='time', autoclose=True, parallel=True).sic\n",
    "\n",
    "ds_79=ds_79.sel(time=slice(str(start_year),str(pred_year-1)))  # end year just has to be way in the future\n",
    "ds_81=ds_81.sel(time=slice('2015',str(pred_year-1)))  # restrict to before prediciton year, lower year not important\n",
    "print(ds_81)\n",
    "print(ds_79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.datetime64('2015-01-07T00:00:00.000000000'),\n",
       " numpy.datetime64('2019-05-20T00:00:00.000000000'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_81.time[0].values, ds_81.time[-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.datetime64('1990-01-07T00:00:00.000000000'),\n",
       " numpy.datetime64('2018-12-30T00:00:00.000000000'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_79.time[0].values, ds_79.time[-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'sic' (time: 1528, y: 448, x: 304)>\n",
      "dask.array<shape=(1528, 448, 304), dtype=float64, chunksize=(52, 448, 304)>\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1990-01-07 1990-01-14 ... 2019-05-20\n",
      "  * x        (x) int64 0 1 2 3 4 5 6 7 8 ... 295 296 297 298 299 300 301 302 303\n",
      "  * y        (y) int64 0 1 2 3 4 5 6 7 8 ... 439 440 441 442 443 444 445 446 447\n",
      "    lat      (x, y) float64 31.1 31.25 31.4 31.55 ... 34.92 34.77 34.62 34.47\n",
      "    lon      (x, y) float64 168.3 168.4 168.5 168.7 ... -9.745 -9.872 -9.999\n",
      "    xm       (x) int64 -3850000 -3825000 -3800000 ... 3675000 3700000 3725000\n",
      "    ym       (y) int64 5850000 5825000 5800000 ... -5275000 -5300000 -5325000\n",
      "    year     (time) int64 1990 1990 1990 1990 1990 ... 2019 2019 2019 2019 2019\n",
      "    week     (time) int64 1 2 3 4 5 6 7 8 9 10 ... 11 12 13 14 15 16 17 18 19 20\n"
     ]
    }
   ],
   "source": [
    "# Combine bootstrap with NASA NRT\n",
    "da_sic = ds_79.combine_first(ds_81)  # takes ds_79 as priority\n",
    "\n",
    "#da_sic=ds_81  # for testing\n",
    "# add year coordinate\n",
    "year_all = [x.year for x in pd.to_datetime(da_sic.time.values)]\n",
    "da_sic.coords['year'] = xr.DataArray(year_all, dims='time', coords={'time':da_sic.time})\n",
    "\n",
    "# put week coordinate back since combine first rubbed them out\n",
    "DOY = [x.timetuple().tm_yday for x in pd.to_datetime(da_sic.time.values)]\n",
    "weeks= np.ceil(np.divide(DOY,7))\n",
    "weeks = weeks.astype(int)\n",
    "da_sic.coords['week'] = xr.DataArray(weeks, dims='time', coords={'time':da_sic.time})\n",
    "print(da_sic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_79 = None\n",
    "ds_81 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot so we are sure this is going right\n",
    "ocnmask = da_sic.isel(time=-30).notnull()  # take a value near the end when not likely to have missing values\n",
    "ocnmask.name = 'oceanmask'\n",
    "#print(ocnmask)\n",
    "\n",
    "PlotTest = False\n",
    "if PlotTest:\n",
    "    tmpsic=da_sic.isel(time=30) # save one time at random for plot verification\n",
    "    #tmpsic=da_sic.mean('time')\n",
    "    #print(tmpsic)\n",
    "\n",
    "    # plot one time at random to ensure it is about right Nplots has to be one more than you'd think\n",
    "    (f, axes) = ice_plot.multi_polar_axis(ncols=2, nrows=1, Nplots = 3, sizefcter=3)\n",
    "    tmpsic.plot.pcolormesh(cmap='Reds',ax=axes[0], x='lon', y='lat',transform=ccrs.PlateCarree())\n",
    "    ocnmask.plot.pcolormesh(cmap='Reds',ax=axes[1], x='lon', y='lat',transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climatology forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestPlot = False\n",
    "if TestPlot:\n",
    "\n",
    "    # equal to code in mertics.py put here for testing\n",
    "    from scipy import stats\n",
    "    import statsmodels.api as sm\n",
    "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "\n",
    "    def _fitparams(x=None, y=None, dummy=None):                                                                                           \n",
    "\n",
    "        # Drop indices where y are missing                                                                  \n",
    "        nonans = np.isnan(y)\n",
    "        x_nonans = x[~nonans]\n",
    "        y_nonans = y[~nonans]\n",
    "\n",
    "        if y_nonans.size == 0:                                                                                         \n",
    "            fitparm = np.empty([3]) * np.nan\n",
    "        else:\n",
    "            sumy = np.sum(y_nonans)\n",
    "            leny = 1.0*np.size(y_nonans)\n",
    "            fitparm = np.zeros(3)\n",
    "            print('sum len ',sumy,leny)\n",
    "            if (sumy>0. and sumy<leny):\n",
    "                lowess = sm.nonparametric.lowess(y_nonans, x_nonans, frac=.3)  # higher frac is smoother\n",
    "\n",
    "                # unpack the lowess smoothed points to their values\n",
    "                lowess_y = list(zip(*lowess))[1]\n",
    "                #print(lowess_y) # a smooted version of y without extrema\n",
    "\n",
    "                fitparm = np.polyfit(x, lowess_y, 2)\n",
    "            elif (sumy==leny):\n",
    "                fitparm[2] = 1.0\n",
    "\n",
    "        return fitparm\n",
    "\n",
    "    # explore the new method\n",
    "    cweek = 20\n",
    "\n",
    "    # Select current week of year\n",
    "    da_cweek = da_sic.where(da_sic.week==cweek, drop=True).swap_dims({'time':'year'})\n",
    "\n",
    "    ytrain=da_cweek[:,200,150].values\n",
    "#    ytrain=da_cweek[:,200,200].values  # has 0.9 to 1 range\n",
    "#    ytrain=da_cweek[:,200,100].values   # strange high values\n",
    "#    ytrain=da_cweek[:,225,130].values  # very high values\n",
    "    ytrain = ytrain*0.\n",
    "    ytrain = np.ones(29)\n",
    "    print(ytrain)\n",
    "\n",
    "    cyears=np.arange(start_year,pred_year,1)\n",
    "#    print('cyears ',cyears)\n",
    "    origpred=metrics._lrm(cyears, ytrain, pred_year)  # old method with linear fit\n",
    "    pfit =_fitparams(cyears, ytrain)  # new method local for mucking\n",
    "    pfit2 = metrics._lowessfit(cyears, ytrain)  # new method in metric.py\n",
    "    print(pfit)\n",
    "    print(pfit2)\n",
    "\n",
    "    fitfun = np.poly1d(pfit)\n",
    "    fitfun2 = np.poly1d(pfit2)\n",
    "    \n",
    "    newpred = fitfun(pred_year)\n",
    "    newpred2 = fitfun2(pred_year)\n",
    "    \n",
    "    # can I reconstruct it by hand (yes)\n",
    "    tmp=cyears**2*pfit[0]+cyears*pfit[1]+pfit[2]\n",
    "    tmp2=cyears**2*pfit2[0]+cyears*pfit2[1]+pfit2[2]\n",
    "\n",
    "    #x[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]\n",
    "\n",
    "    print('linear fit in red ',origpred)\n",
    "    print('new fit in blue ',newpred)\n",
    "    print('   should be same ',newpred2)\n",
    "\n",
    "    f = plt.figure()\n",
    "    plt.plot(cyears,ytrain,marker='o',markersize=10,color='k')\n",
    "    plt.plot(pred_year,origpred,marker='o',markersize=12,color='r')\n",
    "    plt.plot(pred_year,newpred,marker='o',markersize=10,color='b')\n",
    "    plt.plot(pred_year,newpred2,marker='*',markersize=10,color='g')\n",
    "    plt.plot(cyears,tmp,marker='o',markersize=10,color='c')\n",
    "    plt.plot(cyears,tmp2,marker='o',markersize=10,color='m')\n",
    "\n",
    "    print('green/cyan dots are quadratic fit to lowess smoothed data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   this worked very poorly \n",
    "TestPlot = False\n",
    "if TestPlot:\n",
    "\n",
    "    from scipy.special import logit, expit\n",
    "\n",
    "    def _fitparams2(x=None, y=None, dummy=None):                                                                                           \n",
    "        # Drop indices where y are missing                                                                  \n",
    "        nonans = np.isnan(y)\n",
    "        x_nonans = x[~nonans]\n",
    "        y_nonans = y[~nonans]\n",
    "\n",
    "        if y_nonans.size == 0:                                                                                         \n",
    "            fitparm = np.empty([3]) * np.nan\n",
    "        else:\n",
    "            ytrans = logit(y_nonans)\n",
    "            ytrans = np.clip(ytrans, -500, 500)\n",
    "            print('ytrans ', ytrans)\n",
    "            fitparm = np.polyfit(x, ytrans, 2)\n",
    "        return fitparm\n",
    "\n",
    "TestPlot = False\n",
    "if TestPlot:\n",
    "    # explore the new method\n",
    "    cweek = 20\n",
    "\n",
    "    # Select current week of year\n",
    "    da_cweek = da_sic.where(da_sic.week==cweek, drop=True).swap_dims({'time':'year'})\n",
    "\n",
    "    ytrain=da_cweek[:,200,150].values\n",
    "#    ytrain=da_cweek[:,200,200].values  # has 0.9 to 1 range\n",
    "#    ytrain=da_cweek[:,200,100].values   # strange high values\n",
    "#    ytrain=da_cweek[:,225,130].values  # very high values\n",
    "\n",
    "    print(ytrain)\n",
    "\n",
    "    cyears=np.arange(start_year,pred_year,1)\n",
    "#    print('cyears ',cyears)\n",
    "    \n",
    "    pfitlogit =_fitparams2(cyears, ytrain)  # new method with logit\n",
    "    fitfun3 = np.poly1d(pfitlogit)\n",
    "    newpred3 = expit(fitfun3(pred_year))\n",
    "    logitfit = expit(fitfun3(cyears))\n",
    "\n",
    "#    print('logit stuff ', ylogitfit, logitpred, newpred3)\n",
    "    print('logitfit ',logitfit)\n",
    "    \n",
    "    f, axarr = plt.subplots(2, sharex=True)\n",
    "    axarr[0].plot(cyears,ytrain,marker='o',markersize=10,color='k')\n",
    "    axarr[0].plot(cyears,logitfit,marker='o',markersize=8,color='m')\n",
    "    axarr[0].plot(pred_year,newpred3,marker='o',markersize=8,color='m')\n",
    "    axarr[0].set_title('fit using logit transpformed back to normal space')\n",
    "    axarr[1].plot(cyears,logit(ytrain)-0.5,marker='o',markersize=10,color='k')\n",
    "    axarr[1].plot(cyears,fitfun3(cyears),marker='o',markersize=10,color='m')\n",
    "    axarr[1].set_title('fit in logit space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week01_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week02_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week03_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week04_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week05_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week06_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week07_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week08_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week09_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week10_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week11_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week12_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week13_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week14_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week15_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week16_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week17_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week18_1990_2019_SICfitparams.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week19_1990_2019_SICfitparams.nc  has already been done\n",
      "Processing week  20  of  20  for predicting year  2020\n",
      "output this to file  <xarray.DataArray 'fitparams' (time: 1, y: 448, x: 304, pdim: 3)>\n",
      "dask.array<shape=(1, 448, 304, 3), dtype=float64, chunksize=(1, 448, 304, 3)>\n",
      "Coordinates:\n",
      "  * x        (x) int64 0 1 2 3 4 5 6 7 8 ... 295 296 297 298 299 300 301 302 303\n",
      "  * y        (y) int64 0 1 2 3 4 5 6 7 8 ... 439 440 441 442 443 444 445 446 447\n",
      "    lat      (x, y) float64 dask.array<shape=(304, 448), chunksize=(304, 448)>\n",
      "    lon      (x, y) float64 dask.array<shape=(304, 448), chunksize=(304, 448)>\n",
      "    xm       (x) int64 dask.array<shape=(304,), chunksize=(304,)>\n",
      "    ym       (y) int64 dask.array<shape=(448,), chunksize=(448,)>\n",
      "  * pdim     (pdim) int64 0 1 2\n",
      "    week     int64 20\n",
      "  * time     (time) datetime64[ns] 2020-05-19\n",
      "Saved /home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week20_1990_2019_SICfitparams.nc\n"
     ]
    }
   ],
   "source": [
    "# This is the part that fits the weekly data, after lowess smoothing\n",
    "# it is pretty slow (couple of hours to fit 52 weeks)\n",
    "\n",
    "#pred_year = 2019  # had to force past years but now keep at current year for updates\n",
    "maxweeks = da_sic.sel(time=slice(str(pred_year-1),str(pred_year-1))).week.max().values\n",
    "\n",
    "for cweek in np.arange(1,maxweeks+1,1):\n",
    "\n",
    "    file_out = os.path.join(mod_dir, cmod, runType, 'param_weekly', \n",
    "                            str(pred_year)+'_week'+format(cweek, '02')+'_'+str(start_year)+'_'+str(pred_year - 1)+'_SICfitparams.nc')\n",
    "\n",
    "#    print(file_out)\n",
    "#    diehere\n",
    "    if ((os.path.isfile(file_out)) & (cweek<maxweeks)): # force redo last two week each time\n",
    "        print(file_out,' has already been done')\n",
    "        continue\n",
    "\n",
    "    print(\"Processing week \",cweek,\" of \",maxweeks,\" for predicting year \",pred_year)\n",
    "\n",
    "    # Select current week of year\n",
    "    da_cweek = da_sic.where(da_sic.week==cweek, drop=True).swap_dims({'time':'year'})\n",
    "    \n",
    "    # Split by train and validate years (e.g. 1990 to 2018 for pred_year of 2019)\n",
    "    da_train = da_cweek.sel(year=slice(start_year, pred_year - 1)) #.where(ocnmask) made it much slower\n",
    "    \n",
    "#    print('send this to fit routine ',da_train.chunk({'year': -1}))\n",
    "    ds_pred = metrics.LowessQuadFit(da_train.chunk({'year': -1}), 'year') # Have to rechunk year into one big one\n",
    "\n",
    "    # tidy up the dataset\n",
    "    ds_pred.coords['week'] = cweek\n",
    "    ds_pred.name = 'fitparams'\n",
    "    \n",
    "    # Move back to actual (valid_time) space\n",
    "    ds_pred = ds_pred.expand_dims('time')\n",
    "    ds_pred.coords['time'] = xr.DataArray([datetime.datetime(pred_year,1,1) + datetime.timedelta(days=int(x-1)) for x in [7*cweek]], dims='time')\n",
    "        \n",
    "    print('output this to file ',ds_pred)\n",
    "\n",
    "    ds_pred.load()  # load before saving forces calculation now\n",
    "\n",
    "    # Save to disk\n",
    "    ds_pred.to_netcdf(file_out)\n",
    "    print(\"Saved\",file_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clim trend extrapolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plots = False\n",
    "\n",
    "if test_plots:\n",
    "\n",
    "    # plot one just to be sure it looks good\n",
    "    cweek=1  # week to read in and plot\n",
    "\n",
    "    # read in current week of year for all years\n",
    "    ds_cweek = da_sic.where(da_sic.week==cweek, drop=True).swap_dims({'time':'year'})\n",
    "\n",
    "    # Split by train and validate years (e.g. 1990 to 2018 for pred_year of 2019)\n",
    "    ds_cweek = ds_cweek.sel(year=slice(start_year, pred_year - 1)) \n",
    "\n",
    "    # read in the fit parameters for this range of years\n",
    "    file_out = os.path.join(mod_dir, cmod, runType, 'param_weekly', \n",
    "                            str(pred_year)+'_week'+format(cweek, '02')+'_'+str(start_year)+'_'+str(pred_year - 1)+'_SICfitparams.nc')\n",
    "\n",
    "    print(file_out)\n",
    "    ds = xr.open_mfdataset(file_out, autoclose=True, parallel=True)\n",
    "\n",
    "    recons=pred_year**2*ds.fitparams.isel(pdim=0,time=0)  +  pred_year*ds.fitparams.isel(pdim=1,time=0) +  ds.fitparams.isel(pdim=2,time=0)\n",
    "    #x[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]\n",
    "    #print(recons)\n",
    "    ocnmask=recons.notnull()\n",
    "#    recons=recons.where(recons>0,other=0).where(ocnmask)\n",
    "#    recons=recons.where(recons<1,other=1).where(ocnmask)\n",
    "    sicmean=ds_cweek.mean('year')\n",
    "\n",
    "    (f, axes) = ice_plot.multi_polar_axis(ncols=5, nrows=1,sizefcter=2)\n",
    "    recons.plot.pcolormesh(cmap='Blues',ax=axes[0], x='lon', y='lat',transform=ccrs.PlateCarree())\n",
    "    axes[0].set_title('Week 1 Fit', fontsize=20)\n",
    "    sicmean.plot.pcolormesh(cmap='Blues',ax=axes[1], x='lon', y='lat',transform=ccrs.PlateCarree())\n",
    "    axes[1].set_title('Past Mean', fontsize=20)\n",
    "    tmp = recons-sicmean\n",
    "    tmp.plot.pcolormesh(cmap='RdYlBu',ax=axes[2], x='lon', y='lat',transform=ccrs.PlateCarree())\n",
    "    axes[2].set_title('Difference', fontsize=20)\n",
    "    ds.fitparams.isel(pdim=0,time=0).plot.pcolormesh(cmap='RdYlBu',ax=axes[3], x='lon', y='lat',transform=ccrs.PlateCarree())\n",
    "    axes[2].set_title('fit param 0', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week01_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week01_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week01_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week02_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week02_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week02_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week03_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week03_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week03_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week04_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week04_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week04_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week05_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week05_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week05_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week06_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week06_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week06_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week07_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week07_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week07_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week08_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week08_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week08_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week09_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week09_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week09_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week10_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week10_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week10_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week11_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week11_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week11_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week12_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week12_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week12_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week13_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week13_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week13_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week14_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week14_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week14_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week15_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week15_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week15_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week16_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week16_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week16_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week17_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week17_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week17_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week18_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week18_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week18_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week19_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week19_1990_2019_SICfitparams.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week19_1990_2019_SIC.nc  has already been done\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week20_1990_2019_SIC.nc\n",
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week20_1990_2019_SICfitparams.nc\n",
      "Saved /home/disk/sipn/nicway/data/model/climatology/forecast/sipn_nc_weekly/2020_week20_1990_2019_SIC.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/core.py:137: RuntimeWarning: invalid value encountered in greater\n",
      "  return func(*args2)\n",
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/dask/core.py:137: RuntimeWarning: invalid value encountered in less\n",
      "  return func(*args2)\n"
     ]
    }
   ],
   "source": [
    "# Compute and Write the climo Trend for each week of the prediction year\n",
    "#pred_year = 2019  # had to force past years but now keep at current year for updates\n",
    "\n",
    "maxweeks = da_sic.sel(time=slice(str(pred_year-1),str(pred_year-1))).week.max().values\n",
    "print(maxweeks)\n",
    "\n",
    "\n",
    "for cweek in np.arange(1,maxweeks+1,1):\n",
    "\n",
    "    if pred_year==2017:  # special case of last week of 2017 made for interpolating\n",
    "        if cweek<52:\n",
    "            continue\n",
    "        file_in = os.path.join(mod_dir, cmod, runType, 'param_weekly', \n",
    "            str(pred_year+1)+'_week'+format(cweek, '02')+'_'+str(start_year)+'_'+str(pred_year)+'_SICfitparams.nc')\n",
    "            \n",
    "    else:\n",
    "        # read in the fit parameters for this range of years\n",
    "        file_in = os.path.join(mod_dir, cmod, runType, 'param_weekly', \n",
    "            str(pred_year)+'_week'+format(cweek, '02')+'_'+str(start_year)+'_'+str(pred_year - 1)+'_SICfitparams.nc')\n",
    "\n",
    "\n",
    "\n",
    "    file_out = os.path.join(mod_dir, cmod, runType, 'sipn_nc_weekly', \n",
    "                                str(pred_year)+'_week'+format(cweek, '02')+'_'+str(start_year)+'_'+str(pred_year - 1)+'_SIC.nc')\n",
    "\n",
    "    print(file_out)\n",
    "    print(file_in)\n",
    "\n",
    "\n",
    "    if ((os.path.isfile(file_out)) & (cweek<maxweeks)): # force redo last week each time\n",
    "        print(file_out,' has already been done')\n",
    "        continue\n",
    "\n",
    "\n",
    "    ds = xr.open_mfdataset(file_in, autoclose=True, parallel=True)\n",
    "\n",
    "    recons=pred_year**2*ds.fitparams.isel(pdim=0,time=0)  +  pred_year*ds.fitparams.isel(pdim=1,time=0) +  ds.fitparams.isel(pdim=2,time=0)\n",
    "    #x[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]\n",
    "    recons.name = 'ClimoTrendSIC'\n",
    "    recons = recons.drop('pdim')\n",
    "    ocnmask=recons.notnull()\n",
    "    recons=recons.where(recons>0,other=0).where(ocnmask)\n",
    "    recons=recons.where(recons<1,other=1).where(ocnmask)\n",
    "    if pred_year==2017: \n",
    "        recons['time'] = recons.time.values - np.timedelta64(365,'D') \n",
    "        print(recons.time)\n",
    "    \n",
    "    recons.to_netcdf(file_out)\n",
    "    print(\"Saved\",file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/data/model/climatology/forecast/param_weekly/2020_week20_1990_2019_SICfitparams.nc\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute anomalies for purpose of computing alpha for damped persistence\n",
    "# not important to redo with more data since 28 years should be plenty to get a good estimate for \n",
    "# no doubt this could be done more elegantly \n",
    "# did not rerun after recomputing the fit params \n",
    "# the change to fitparams is pretty trivial \n",
    "# all I did was force them to be 0,0,0 or 0,0,1 for sic always 0 or 1\n",
    "\n",
    "update = False\n",
    "\n",
    "if update:\n",
    "    start_year=1990\n",
    "    pred_year = 2018  \n",
    "    end_year = pred_year - 1\n",
    "\n",
    "    ds_79 = xr.open_mfdataset(E.obs['NSIDC_0079']['sipn_nc']+'_yearly_byweek/*byweek.nc', concat_dim='time', autoclose=True, parallel=True).sic\n",
    "    ds_79=ds_79.sel(time=slice(str(start_year),str(end_year))) \n",
    "\n",
    "    year_all = [x.year for x in pd.to_datetime(ds_79.time.values)]\n",
    "    ds_79.coords['year'] = xr.DataArray(year_all, dims='time', coords={'time':ds_79.time})\n",
    "\n",
    "    # Write the Anomaly from the ClimoTrend for each week of each year, just use 1990-2017 fit params\n",
    "    for cweek in np.arange(1,da_sic.week.max().values+1,1):\n",
    "\n",
    "        # read in the fit parameters for this range of years\n",
    "        file_in = os.path.join(mod_dir, cmod, runType, 'param_weekly', \n",
    "                                str(pred_year)+'_week'+format(cweek, '02')+'_'+str(start_year)+'_'+str(pred_year - 1)+'_SICfitparams.nc')\n",
    "        ds = xr.open_mfdataset(file_in, autoclose=True, parallel=True)\n",
    "\n",
    "        for cyear in np.arange(start_year, end_year+1, 1):\n",
    "            # read in current week of current year \n",
    "            ds_specific = ds_79.where(ds_79.week==cweek, drop=True).swap_dims({'time':'year'})\n",
    "            ds_specific = ds_specific.where(ds_specific.year==cyear, drop=True)\n",
    "\n",
    "            print('Year ',ds_specific.year.values,' Week ',ds_specific.week.values)\n",
    "\n",
    "            recons=cyear**2*ds.fitparams.isel(pdim=0,time=0) + cyear*ds.fitparams.isel(pdim=1,time=0) + ds.fitparams.isel(pdim=2,time=0)\n",
    "            #x[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]\n",
    "            recons.name = 'sic'\n",
    "            ocnmask=recons.notnull()\n",
    "            recons=recons.where(recons>0,other=0).where(ocnmask)\n",
    "            recons=recons.where(recons<1,other=1).where(ocnmask)\n",
    "\n",
    "            recons['time'].values = ds_specific['time'][0].values\n",
    "            recons.values=ds_specific.values[0]-recons.values\n",
    "    #        print(recons)\n",
    "\n",
    "    #        (f, axes) = ice_plot.multi_polar_axis(ncols=4, nrows=1,sizefcter=2)\n",
    "    #        recons.plot.pcolormesh(cmap='Blues',ax=axes[0], x='lon', y='lat',transform=ccrs.PlateCarree())\n",
    "    #        axes[0].set_title('Week 1 Fit', fontsize=20)\n",
    "\n",
    "            file_out = os.path.join(mod_dir, 'ObsAnomalyWeek', runType, 'sipn_nc', \n",
    "                                    str(cyear)+'_week'+format(cweek, '02')+'_SICanom.nc')\n",
    "            recons.to_netcdf(file_out)\n",
    "            print(\"Saved\",file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS\n",
    "\n",
    "# for cyear in np.arange(start_year, end_year+1, 1):\n",
    "\n",
    "#    indir=os.path.join(mod_dir, 'ObsAnomalyWeek', runType, 'sipn_nc')\n",
    "#    print(indir)\n",
    "\n",
    "#    c_files = sorted(glob.glob(indir+'/'+str(cyear)+'_week'+'*.nc'))\n",
    "\n",
    "#    ds_anom = xr.open_mfdataset(c_files, concat_dim='time')\n",
    "\n",
    "#    file_out = os.path.join(mod_dir, 'ObsAnomalyWeek', runType, 'sipn_nc', str(cyear)+ '_SICanom.nc')\n",
    "\n",
    "#    ds_anom.to_netcdf(file_out)\n",
    "#    print(\"Saved\",file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nic's presentation figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plots = False\n",
    "\n",
    "\n",
    "if test_plots:\n",
    "    fig_dir = '/home/disk/sipn/nicway/Nic/figures/pres/A'\n",
    "\n",
    "    cx = 160\n",
    "    cy = 220\n",
    "\n",
    "    sns.set_context(\"talk\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "    f = plt.figure()\n",
    "    da_train.isel(year=1).T.plot(label='Sea ice Concentration')\n",
    "    plt.plot(cy,cx,marker='o',markersize=10,color='k')\n",
    "    plt.title('')\n",
    "    f_out = os.path.join(fig_dir,'spatial_plot.png')\n",
    "    f.savefig(f_out,bbox_inches='tight', dpi=300)\n",
    "\n",
    "    sns.set_context(\"talk\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "    from scipy import stats\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(da_train.isel(y=cy,x=cx).year.values, da_train.isel(y=cy,x=cx).values)\n",
    "    predict_y = intercept + slope * da_train.isel(y=cy,x=cx).year.values\n",
    "    predict_y\n",
    "\n",
    "    f = plt.figure()\n",
    "    da_train.isel(y=cy,x=cx).plot(color='b',label='Observed')\n",
    "    plt.plot(2018, ds_pred.isel(y=cy,x=cx).values,'r*',label='Predicted',markersize=14)\n",
    "    plt.plot(da_train.isel(y=cy,x=cx).year.values, predict_y,'k--', label='linear least-squares')\n",
    "    plt.title('')\n",
    "    plt.legend(loc='lower left', bbox_to_anchor=(1.03, .7))\n",
    "    plt.ylabel('Sea Ice Concentration (-)')\n",
    "    f_out = os.path.join(fig_dir,'linearfit.png')\n",
    "    f.savefig(f_out,bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
