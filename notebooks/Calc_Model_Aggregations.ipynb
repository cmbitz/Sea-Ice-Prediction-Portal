{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis code is part of the SIPN2 project focused on improving sub-seasonal to seasonal predictions of Arctic Sea Ice. \\nIf you use this code for a publication or presentation, please cite the reference in the README.md on the\\nmain page (https://github.com/NicWayand/ESIO). \\n\\nQuestions or comments should be addressed to nicway@uw.edu\\n\\nCopyright (c) 2018 Nic Wayand\\n\\nGNU General Public License v3.0\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "This code is part of the SIPN2 project focused on improving sub-seasonal to seasonal predictions of Arctic Sea Ice. \n",
    "If you use this code for a publication or presentation, please cite the reference in the README.md on the\n",
    "main page (https://github.com/NicWayand/ESIO). \n",
    "\n",
    "Questions or comments should be addressed to nicway@uw.edu\n",
    "\n",
    "Copyright (c) 2018 Nic Wayand\n",
    "\n",
    "GNU General Public License v3.0\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import matplotlib\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import dask\n",
    "# dask.set_options(get=dask.threaded.get)\n",
    "from dask.distributed import Client\n",
    "\n",
    "# ESIO Imports\n",
    "\n",
    "from esio import EsioData as ed\n",
    "from esio import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:53514 remote=tcp://127.0.0.1:33373>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:53826 remote=tcp://127.0.0.1:33373>\n"
     ]
    }
   ],
   "source": [
    "def Update_Model_Aggs():\n",
    "    '''Calculates pan-arctic and regional extents from different forecast models'''\n",
    "    \n",
    "    E = ed.EsioData.load()\n",
    "    model_dir = E.model_dir\n",
    "    # Directories\n",
    "    # Define models to plot\n",
    "    all_models = list(E.model.keys())\n",
    "    all_models = [x for x in all_models if x not in ['piomas','MME','MME_NEW']] # remove some models\n",
    "    all_models = ['ecmwfsipn'] # metreofr, ecmwf, cma\n",
    "    runType='forecast'\n",
    "    updateall = False\n",
    "\n",
    "    ds_region = xr.open_mfdataset(os.path.join(E.grid_dir, 'sio_2016_mask_Update.nc')).load()\n",
    "\n",
    "    for model in all_models:\n",
    "        print(model)\n",
    "\n",
    "        data_dir = E.model[model][runType]['sipn_nc']\n",
    "        data_out = os.path.join(model_dir, model, runType, 'sipn_nc_agg')\n",
    "        if not os.path.exists(data_out):\n",
    "            os.makedirs(data_out)\n",
    "\n",
    "        all_files = glob.glob(os.path.join(data_dir, '*.nc'))\n",
    "        print(\"Found \",len(all_files),\" files.\")\n",
    "        if updateall:\n",
    "            print(\"Updating all files...\")\n",
    "        else:\n",
    "            print(\"Only updating new files\")\n",
    "\n",
    "        # Remove any \"empty\" files (sometimes happends with ecmwf downloads)\n",
    "        all_files_new = []\n",
    "        for cf in all_files:\n",
    "            if os.stat(cf).st_size > 0:\n",
    "                all_files_new.append(cf)\n",
    "            else:\n",
    "                print(\"Found empty file: \",cf,\". Consider deleting or redownloading.\")\n",
    "        all_files = sorted(all_files_new) # Replace and sort\n",
    "\n",
    "        # For each file\n",
    "        for cf in all_files:\n",
    "            # Check if already imported and skip (unless updateall flag is True)\n",
    "            # Always import the most recent two months of files (because they get updated)\n",
    "            f_out = os.path.join(data_out, os.path.basename(cf)) # netcdf file out \n",
    "            if not updateall:\n",
    "                 if (os.path.isfile(f_out)) & (cf not in all_files[-2:]):\n",
    "                    #print(\"Skipping \", os.path.basename(cf), \" already imported.\")\n",
    "                    continue # Skip, file already imported\n",
    "\n",
    "            # running out of memory with this chunk size with S2S perturbed ecmwf, trying different chunk size\n",
    "#            ds = xr.open_mfdataset(cf , chunks={'fore_time':10, 'ensemble': 5, 'init_time': 10, 'nj': 304, 'ni': 448},\n",
    "            ds = xr.open_mfdataset(cf , chunks={'fore_time':60, 'ensemble': 1, 'init_time': 3, 'nj': 304, 'ni': 448},\n",
    "                                  parallel=True) # Works but is not eiffecent 5-15 mins wall time\n",
    "            ds.rename({'nj':'x', 'ni':'y'}, inplace=True)\n",
    "\n",
    "            # Calc panArctic extent\n",
    "            da_panE = metrics.calc_extent(da=ds.sic, region=ds_region)\n",
    "            da_panE['nregions'] = 99\n",
    "            da_panE['region_names'] = 'panArctic'\n",
    "\n",
    "            # Calc Regional extents\n",
    "            da_RegE = metrics.agg_by_domain(da_grid=ds.sic, ds_region=ds_region)\n",
    "\n",
    "            # Merge\n",
    "            ds_out = xr.concat([da_panE, da_RegE], dim='nregions')\n",
    "            ds_out.name = 'Extent'\n",
    "\n",
    "            ds_out.load() # This prevents many errors in the dask graph (I don't know why)\n",
    "            try:\n",
    "                # # Save regridded to netcdf file\n",
    "                ds_out.to_netcdf(f_out)\n",
    "            except: \n",
    "                print('Permission deny error (probably) on ', f_out)\n",
    "                \n",
    "            ds_out = None # Memory clean up\n",
    "            da_panE = None\n",
    "            da_RegE = None\n",
    "            ds = None\n",
    "            print('Saved ', f_out)\n",
    "\n",
    "\n",
    "        print(\"Finished...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/nicway/anaconda3/envs/esio/lib/python3.6/site-packages/distributed/bokeh/core.py:57: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn('\\n' + msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: scheduler='tcp://127.0.0.1:33373' processes=8 cores=16>\n",
      "ukmetofficesipn\n",
      "Found  25  files.\n",
      "Only updating new files\n",
      "Saved  /home/disk/sipn/nicway/data/model/ukmetofficesipn/forecast/sipn_nc_agg/ukmetofficesipn_2019_12_Stereo.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/ukmetofficesipn/forecast/sipn_nc_agg/ukmetofficesipn_2020_01_Stereo.nc\n",
      "Finished...\n",
      "meteofrsipn\n",
      "Found  21  files.\n",
      "Only updating new files\n",
      "Saved  /home/disk/sipn/nicway/data/model/meteofrsipn/forecast/sipn_nc_agg/meteofrsipn_2019_12_Stereo.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/meteofrsipn/forecast/sipn_nc_agg/meteofrsipn_2020_01_Stereo.nc\n",
      "Finished...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Start up Client\n",
    "    client = Client(n_workers=8)\n",
    "    print(client)\n",
    "    \n",
    "    # Call function\n",
    "    Update_Model_Aggs()\n",
    "    \n",
    "    # Close it down\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
