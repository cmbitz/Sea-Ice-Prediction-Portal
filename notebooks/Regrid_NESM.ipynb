{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCC changed nothing of significance here. Just put in some print statements to discover that the problem \\nwas that there was only one file retrieved from the unzipping process on a couple of days and that \\nprevented the code from running because it concatinates the files and uses the time between subsequent files to \\ndefine the timestep\\n\\nI managed to just unzip the files again and get the files to work\\nfor all but one case. In that case the files were there but seemed to have an index error of some sort\\nso I put an error check in here just to be safe\\n\\n        if len(c_files)==1:\\n            print(\"Skipping because regridding fails when only one time\")\\n            continue \\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "CC changed nothing of significance here. Just put in some print statements to discover that the problem \n",
    "was that there was only one file retrieved from the unzipping process on a couple of days and that \n",
    "prevented the code from running because it concatinates the files and uses the time between subsequent files to \n",
    "define the timestep\n",
    "\n",
    "I managed to just unzip the files again and get the files to work\n",
    "for all but one case. In that case the files were there but seemed to have an index error of some sort\n",
    "so I put an error check in here just to be safe\n",
    "\n",
    "        if len(c_files)==1:\n",
    "            print(\"Skipping because regridding fails when only one time\")\n",
    "            continue \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This code is part of the SIPN2 project focused on improving sub-seasonal to seasonal predictions of Arctic Sea Ice. \n",
    "If you use this code for a publication or presentation, please cite the reference in the README.md on the\n",
    "main page (https://github.com/NicWayand/ESIO). \n",
    "\n",
    "Questions or comments should be addressed to nicway@uw.edu\n",
    "\n",
    "Copyright (c) 2018 Nic Wayand\n",
    "\n",
    "GNU General Public License v3.0\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Standard Imports\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import matplotlib\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# ESIO Imports\n",
    "\n",
    "from esio import EsioData as ed\n",
    "from esio import import_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General plotting settings\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context(\"talk\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = ed.EsioData.load()\n",
    "# Directories\n",
    "all_models=['usnavygofs','usnavyncep','usnavysipn']\n",
    "runType='forecast'\n",
    "updateall = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stero_grid_file = E.obs['NSIDC_0051']['grid']\n",
    "obs_grid = import_data.load_grid_info(stero_grid_file, model='NSIDC')\n",
    "# Ensure latitude is within bounds (-90 to 90)\n",
    "# Have to do this because grid file has 90.000001\n",
    "obs_grid['lat_b'] = obs_grid.lat_b.where(obs_grid.lat_b < 90, other = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regridding Options\n",
    "# method='conservative_normed' # ['bilinear', 'conservative', 'nearest_s2d', 'nearest_d2s', 'patch']\n",
    "method = 'nearest_s2d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set models that are different\n",
    "var_dic = {'aice':'sic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regridding  usnavygofs ...\n",
      "Found  588  initialization times.\n",
      "Only updating new files\n",
      "Skipping  2018010112  already imported.\n",
      "Skipping  2018010212  already imported.\n",
      "Skipping  2018010312  already imported.\n",
      "Skipping  2018010412  already imported.\n",
      "Skipping  2018010512  already imported.\n",
      "Skipping  2018010612  already imported.\n",
      "Skipping  2018010712  already imported.\n",
      "Skipping  2018010812  already imported.\n",
      "Skipping  2018010912  already imported.\n",
      "Skipping  2018011012  already imported.\n",
      "Skipping  2018011112  already imported.\n",
      "Skipping  2018011212  already imported.\n",
      "Skipping  2018011312  already imported.\n",
      "Skipping  2018011412  already imported.\n",
      "Skipping  2018011512  already imported.\n",
      "Skipping  2018011612  already imported.\n",
      "Skipping  2018011712  already imported.\n",
      "Skipping  2018011812  already imported.\n",
      "Skipping  2018011912  already imported.\n",
      "Skipping  2018012012  already imported.\n",
      "Skipping  2018012112  already imported.\n",
      "Skipping  2018012212  already imported.\n",
      "Skipping  2018012312  already imported.\n",
      "Skipping  2018012412  already imported.\n",
      "Skipping  2018012512  already imported.\n",
      "Skipping  2018012612  already imported.\n",
      "Skipping  2018012712  already imported.\n",
      "Skipping  2018012812  already imported.\n",
      "Skipping  2018012912  already imported.\n",
      "Skipping  2018013012  already imported.\n",
      "Skipping  2018013112  already imported.\n",
      "Skipping  2018020112  already imported.\n",
      "Skipping  2018020212  already imported.\n",
      "Skipping  2018020312  already imported.\n",
      "Skipping  2018020412  already imported.\n",
      "Skipping  2018020512  already imported.\n",
      "Skipping  2018020612  already imported.\n",
      "Skipping  2018020712  already imported.\n",
      "Skipping  2018020812  already imported.\n",
      "Skipping  2018020912  already imported.\n",
      "Skipping  2018021012  already imported.\n",
      "Skipping  2018021112  already imported.\n",
      "Skipping  2018021212  already imported.\n",
      "Skipping  2018021312  already imported.\n",
      "Skipping  2018021412  already imported.\n",
      "Skipping  2018021512  already imported.\n",
      "Skipping  2018021612  already imported.\n",
      "Skipping  2018021712  already imported.\n",
      "Skipping  2018021812  already imported.\n",
      "Skipping  2018021912  already imported.\n",
      "Skipping  2018022012  already imported.\n",
      "Skipping  2018022112  already imported.\n",
      "Skipping  2018022212  already imported.\n",
      "Skipping  2018022312  already imported.\n",
      "Skipping  2018022412  already imported.\n",
      "Skipping  2018022512  already imported.\n",
      "Skipping  2018022612  already imported.\n",
      "Skipping  2018022712  already imported.\n",
      "Skipping  2018022812  already imported.\n",
      "Skipping  2018030112  already imported.\n",
      "Skipping  2018030212  already imported.\n",
      "Skipping  2018030312  already imported.\n",
      "Skipping  2018030412  already imported.\n",
      "Skipping  2018030512  already imported.\n",
      "Skipping  2018030612  already imported.\n",
      "Skipping  2018030712  already imported.\n",
      "Skipping  2018030812  already imported.\n",
      "Skipping  2018030912  already imported.\n",
      "Skipping  2018031012  already imported.\n",
      "Skipping  2018031112  already imported.\n",
      "Skipping  2018031212  already imported.\n",
      "Skipping  2018031312  already imported.\n",
      "Skipping  2018031412  already imported.\n",
      "Skipping  2018031512  already imported.\n",
      "Skipping  2018031612  already imported.\n",
      "Skipping  2018031712  already imported.\n",
      "Skipping  2018031812  already imported.\n",
      "Skipping  2018032012  already imported.\n",
      "Skipping  2018032112  already imported.\n",
      "Skipping  2018032212  already imported.\n",
      "Skipping  2018032312  already imported.\n",
      "Skipping  2018032412  already imported.\n",
      "Skipping  2018032512  already imported.\n",
      "Skipping  2018032612  already imported.\n",
      "Skipping  2018032712  already imported.\n",
      "Skipping  2018032812  already imported.\n",
      "Skipping  2018032912  already imported.\n",
      "Skipping  2018033012  already imported.\n",
      "Skipping  2018033112  already imported.\n",
      "Skipping  2018040112  already imported.\n",
      "Skipping  2018040212  already imported.\n",
      "Skipping  2018040312  already imported.\n",
      "Skipping  2018040412  already imported.\n",
      "Skipping  2018040512  already imported.\n",
      "Skipping  2018040612  already imported.\n",
      "Skipping  2018040712  already imported.\n",
      "Skipping  2018040812  already imported.\n",
      "Skipping  2018040912  already imported.\n",
      "Skipping  2018041012  already imported.\n",
      "Skipping  2018041112  already imported.\n",
      "Skipping  2018041212  already imported.\n",
      "Skipping  2018041312  already imported.\n",
      "Skipping  2018041412  already imported.\n",
      "Skipping  2018041512  already imported.\n",
      "Skipping  2018041612  already imported.\n",
      "Skipping  2018041712  already imported.\n",
      "Skipping  2018041812  already imported.\n",
      "Skipping  2018041912  already imported.\n",
      "Skipping  2018042012  already imported.\n",
      "Skipping  2018042112  already imported.\n",
      "Skipping  2018042212  already imported.\n",
      "Skipping  2018042312  already imported.\n",
      "Skipping  2018042412  already imported.\n",
      "Skipping  2018042512  already imported.\n",
      "Skipping  2018042612  already imported.\n",
      "Skipping  2018042712  already imported.\n",
      "Skipping  2018042812  already imported.\n",
      "Skipping  2018042912  already imported.\n",
      "Skipping  2018043012  already imported.\n",
      "Skipping  2018050112  already imported.\n",
      "Skipping  2018050212  already imported.\n",
      "Skipping  2018050312  already imported.\n",
      "Skipping  2018050412  already imported.\n",
      "Skipping  2018050512  already imported.\n",
      "Skipping  2018050612  already imported.\n",
      "Skipping  2018050712  already imported.\n",
      "Skipping  2018050812  already imported.\n",
      "Skipping  2018050912  already imported.\n",
      "Skipping  2018051012  already imported.\n",
      "Skipping  2018051112  already imported.\n",
      "Skipping  2018051212  already imported.\n",
      "Skipping  2018051312  already imported.\n",
      "Skipping  2018051412  already imported.\n",
      "Skipping  2018051512  already imported.\n",
      "Skipping  2018051612  already imported.\n",
      "Skipping  2018051712  already imported.\n",
      "Skipping  2018051812  already imported.\n",
      "Skipping  2018051912  already imported.\n",
      "Skipping  2018052012  already imported.\n",
      "Skipping  2018052112  already imported.\n",
      "Skipping  2018052212  already imported.\n",
      "Skipping  2018052312  already imported.\n",
      "Skipping  2018052412  already imported.\n",
      "Skipping  2018052512  already imported.\n",
      "Skipping  2018052612  already imported.\n",
      "Skipping  2018052712  already imported.\n",
      "Skipping  2018052812  already imported.\n",
      "Skipping  2018052912  already imported.\n",
      "Skipping  2018053012  already imported.\n",
      "Skipping  2018053112  already imported.\n",
      "Skipping  2018060112  already imported.\n",
      "Skipping  2018060212  already imported.\n",
      "Skipping  2018060312  already imported.\n",
      "Skipping  2018060412  already imported.\n",
      "Skipping  2018060512  already imported.\n",
      "Skipping  2018060612  already imported.\n",
      "Skipping  2018060712  already imported.\n",
      "Skipping  2018060812  already imported.\n",
      "Skipping  2018060912  already imported.\n",
      "Skipping  2018061012  already imported.\n",
      "Skipping  2018061112  already imported.\n",
      "Skipping  2018061212  already imported.\n",
      "Skipping  2018061312  already imported.\n",
      "Skipping  2018061412  already imported.\n",
      "Skipping  2018061512  already imported.\n",
      "Skipping  2018061612  already imported.\n",
      "Skipping  2018061712  already imported.\n",
      "Skipping  2018061812  already imported.\n",
      "Skipping  2018061912  already imported.\n",
      "Skipping  2018062012  already imported.\n",
      "Skipping  2018062112  already imported.\n",
      "Skipping  2018062212  already imported.\n",
      "Skipping  2018062312  already imported.\n",
      "Skipping  2018062412  already imported.\n",
      "Skipping  2018062512  already imported.\n",
      "Skipping  2018062612  already imported.\n",
      "Skipping  2018062712  already imported.\n",
      "Skipping  2018062812  already imported.\n",
      "Skipping  2018062912  already imported.\n",
      "Skipping  2018063012  already imported.\n",
      "Skipping  2018070112  already imported.\n",
      "Skipping  2018070212  already imported.\n",
      "Skipping  2018070312  already imported.\n",
      "Skipping  2018070412  already imported.\n",
      "Skipping  2018070512  already imported.\n",
      "Skipping  2018070612  already imported.\n",
      "Skipping  2018070712  already imported.\n",
      "Skipping  2018070812  already imported.\n",
      "Skipping  2018070912  already imported.\n",
      "Skipping  2018071012  already imported.\n",
      "Skipping  2018071112  already imported.\n",
      "Skipping  2018071212  already imported.\n",
      "Skipping  2018071312  already imported.\n",
      "Skipping  2018071412  already imported.\n",
      "Skipping  2018071512  already imported.\n",
      "Skipping  2018071612  already imported.\n",
      "Skipping  2018071712  already imported.\n",
      "Skipping  2018071812  already imported.\n",
      "Skipping  2018071912  already imported.\n",
      "Skipping  2018072012  already imported.\n",
      "Skipping  2018072112  already imported.\n",
      "Skipping  2018072212  already imported.\n",
      "Skipping  2018072312  already imported.\n",
      "Skipping  2018072412  already imported.\n",
      "Skipping  2018072512  already imported.\n",
      "Skipping  2018072612  already imported.\n",
      "Skipping  2018072712  already imported.\n",
      "Skipping  2018072812  already imported.\n",
      "Skipping  2018072912  already imported.\n",
      "Skipping  2018073012  already imported.\n",
      "Skipping  2018073112  already imported.\n",
      "Skipping  2018080112  already imported.\n",
      "Skipping  2018080212  already imported.\n",
      "Skipping  2018080312  already imported.\n",
      "Skipping  2018080412  already imported.\n",
      "Skipping  2018080512  already imported.\n",
      "Skipping  2018080612  already imported.\n",
      "Skipping  2018080712  already imported.\n",
      "Skipping  2018080812  already imported.\n",
      "Skipping  2018080912  already imported.\n",
      "Skipping  2018081012  already imported.\n",
      "Skipping  2018081112  already imported.\n",
      "Skipping  2018081212  already imported.\n",
      "Skipping  2018081312  already imported.\n",
      "Skipping  2018081412  already imported.\n",
      "Skipping  2018081512  already imported.\n",
      "Skipping  2018081612  already imported.\n",
      "Skipping  2018081712  already imported.\n",
      "Skipping  2018081812  already imported.\n",
      "Skipping  2018081912  already imported.\n",
      "Skipping  2018082012  already imported.\n",
      "Skipping  2018082112  already imported.\n",
      "Skipping  2018082212  already imported.\n",
      "Skipping  2018082312  already imported.\n",
      "Skipping  2018082412  already imported.\n",
      "Skipping  2018082512  already imported.\n",
      "Skipping  2018082612  already imported.\n",
      "Skipping  2018082712  already imported.\n",
      "Skipping  2018082812  already imported.\n",
      "Skipping  2018082912  already imported.\n",
      "Skipping  2018083012  already imported.\n",
      "Skipping  2018083112  already imported.\n",
      "Skipping  2018090112  already imported.\n",
      "Skipping  2018090212  already imported.\n",
      "Skipping  2018090312  already imported.\n",
      "Skipping  2018090412  already imported.\n",
      "Skipping  2018090512  already imported.\n",
      "Skipping  2018090612  already imported.\n",
      "Skipping  2018090712  already imported.\n",
      "Skipping  2018090812  already imported.\n",
      "Skipping  2018090912  already imported.\n",
      "Skipping  2018091012  already imported.\n",
      "Skipping  2018091112  already imported.\n",
      "Skipping  2018091212  already imported.\n",
      "Skipping  2018091312  already imported.\n",
      "Skipping  2018091412  already imported.\n",
      "Skipping  2018091512  already imported.\n",
      "Skipping  2018091612  already imported.\n",
      "Skipping  2018091712  already imported.\n",
      "Skipping  2018091812  already imported.\n",
      "Skipping  2018091912  already imported.\n",
      "Skipping  2018092012  already imported.\n",
      "Skipping  2018092112  already imported.\n",
      "Skipping  2018092212  already imported.\n",
      "Skipping  2018092312  already imported.\n",
      "Skipping  2018092412  already imported.\n",
      "Skipping  2018092512  already imported.\n",
      "Skipping  2018092612  already imported.\n",
      "Skipping  2018092712  already imported.\n",
      "Skipping  2018092812  already imported.\n",
      "Skipping  2018092912  already imported.\n",
      "Skipping  2018093012  already imported.\n",
      "Skipping  2018100112  already imported.\n",
      "Skipping  2018100212  already imported.\n",
      "Skipping  2018100312  already imported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping  2018100412  already imported.\n",
      "Skipping  2018100512  already imported.\n",
      "Skipping  2018100612  already imported.\n",
      "Skipping  2018100712  already imported.\n",
      "Skipping  2018100812  already imported.\n",
      "Skipping  2018100912  already imported.\n",
      "Skipping  2018101012  already imported.\n",
      "Skipping  2018101112  already imported.\n",
      "Skipping  2018101212  already imported.\n",
      "Skipping  2018101312  already imported.\n",
      "Skipping  2018101412  already imported.\n",
      "Skipping  2018101512  already imported.\n",
      "Skipping  2018101612  already imported.\n",
      "Skipping  2018101712  already imported.\n",
      "Skipping  2018101812  already imported.\n",
      "Skipping  2018101912  already imported.\n",
      "Skipping  2018102012  already imported.\n",
      "Skipping  2018102112  already imported.\n",
      "Skipping  2018102212  already imported.\n",
      "Skipping  2018102312  already imported.\n",
      "Skipping  2018102412  already imported.\n",
      "Skipping  2018102512  already imported.\n",
      "Skipping  2018102612  already imported.\n",
      "Skipping  2018102712  already imported.\n",
      "Skipping  2018102812  already imported.\n",
      "Skipping  2018102912  already imported.\n",
      "Skipping  2018103012  already imported.\n",
      "Skipping  2018103112  already imported.\n",
      "Skipping  2018110112  already imported.\n",
      "Skipping  2018110212  already imported.\n",
      "Skipping  2018110312  already imported.\n",
      "Skipping  2018110412  already imported.\n",
      "Skipping  2018110512  already imported.\n",
      "Skipping  2018110612  already imported.\n",
      "Skipping  2018110712  already imported.\n",
      "Skipping  2018110812  already imported.\n",
      "Skipping  2018110912  already imported.\n",
      "Skipping  2018111012  already imported.\n",
      "Skipping  2018111112  already imported.\n",
      "Skipping  2018111212  already imported.\n",
      "Skipping  2018111312  already imported.\n",
      "Skipping  2018111412  already imported.\n",
      "Skipping  2018111512  already imported.\n",
      "Skipping  2018111612  already imported.\n",
      "Skipping  2018111712  already imported.\n",
      "Skipping  2018111812  already imported.\n",
      "Skipping  2018111912  already imported.\n",
      "Skipping  2018112012  already imported.\n",
      "Skipping  2018112112  already imported.\n",
      "Skipping  2018112212  already imported.\n",
      "Skipping  2018112312  already imported.\n",
      "Skipping  2018112412  already imported.\n",
      "Skipping  2018112512  already imported.\n",
      "Skipping  2018112612  already imported.\n",
      "Skipping  2018112712  already imported.\n",
      "Skipping  2018112812  already imported.\n",
      "Skipping  2018112912  already imported.\n",
      "Skipping  2018113012  already imported.\n",
      "Skipping  2018120112  already imported.\n",
      "Skipping  2018120212  already imported.\n",
      "Skipping  2018120312  already imported.\n",
      "Skipping  2018120412  already imported.\n",
      "Skipping  2018120512  already imported.\n",
      "Skipping  2018120612  already imported.\n",
      "Skipping  2018120712  already imported.\n",
      "Skipping  2018120812  already imported.\n",
      "Skipping  2018120912  already imported.\n",
      "Skipping  2018121012  already imported.\n",
      "Skipping  2018121112  already imported.\n",
      "Skipping  2018121212  already imported.\n",
      "Skipping  2018121312  already imported.\n",
      "Skipping  2018121412  already imported.\n",
      "Skipping  2018121512  already imported.\n",
      "Skipping  2018121612  already imported.\n",
      "Skipping  2018121712  already imported.\n",
      "Skipping  2018121812  already imported.\n",
      "Skipping  2018121912  already imported.\n",
      "Skipping  2018122012  already imported.\n",
      "Skipping  2018122112  already imported.\n",
      "Skipping  2018122212  already imported.\n",
      "Skipping  2018122312  already imported.\n",
      "Skipping  2018122412  already imported.\n",
      "Skipping  2018122512  already imported.\n",
      "Skipping  2018122612  already imported.\n",
      "Skipping  2018122712  already imported.\n",
      "Skipping  2018122812  already imported.\n",
      "Skipping  2018122912  already imported.\n",
      "Skipping  2018123012  already imported.\n",
      "Skipping  2019010112  already imported.\n",
      "Skipping  2019010212  already imported.\n",
      "Skipping  2019010312  already imported.\n",
      "Skipping  2019010412  already imported.\n",
      "Skipping  2019010512  already imported.\n",
      "Skipping  2019010612  already imported.\n",
      "Skipping  2019010712  already imported.\n",
      "Skipping  2019010812  already imported.\n",
      "Skipping  2019011012  already imported.\n",
      "Skipping  2019011112  already imported.\n",
      "Skipping  2019011212  already imported.\n",
      "Skipping  2019011312  already imported.\n",
      "Skipping  2019011412  already imported.\n",
      "Skipping  2019011512  already imported.\n",
      "Skipping  2019011612  already imported.\n",
      "Skipping  2019011712  already imported.\n",
      "Skipping  2019011812  already imported.\n",
      "Skipping  2019011912  already imported.\n",
      "Skipping  2019012012  already imported.\n",
      "Skipping  2019012112  already imported.\n",
      "Skipping  2019012212  already imported.\n",
      "Skipping  2019012312  already imported.\n",
      "Skipping  2019012412  already imported.\n",
      "Skipping  2019012512  already imported.\n",
      "Skipping  2019012612  already imported.\n",
      "Skipping because regridding fails when only one time\n",
      "Skipping  2019012812  already imported.\n",
      "Skipping  2019012912  already imported.\n",
      "Skipping  2019013012  already imported.\n",
      "Skipping  2019013112  already imported.\n",
      "Skipping  2019020112  already imported.\n",
      "Skipping  2019020212  already imported.\n",
      "Skipping  2019020312  already imported.\n",
      "Skipping  2019020412  already imported.\n",
      "Skipping  2019020612  already imported.\n",
      "Skipping  2019020712  already imported.\n",
      "Skipping  2019020812  already imported.\n",
      "Skipping  2019020912  already imported.\n",
      "Skipping  2019021012  already imported.\n",
      "Skipping  2019021112  already imported.\n",
      "Skipping  2019021412  already imported.\n",
      "Skipping  2019021512  already imported.\n",
      "Skipping  2019021612  already imported.\n",
      "Skipping  2019021712  already imported.\n",
      "Skipping  2019021812  already imported.\n",
      "Skipping  2019021912  already imported.\n",
      "Skipping  2019022012  already imported.\n",
      "Skipping  2019022112  already imported.\n",
      "Skipping  2019022212  already imported.\n",
      "Skipping  2019022312  already imported.\n",
      "Skipping  2019022412  already imported.\n",
      "Skipping  2019022512  already imported.\n",
      "Skipping  2019022612  already imported.\n",
      "Skipping  2019022712  already imported.\n",
      "Skipping  2019022812  already imported.\n",
      "Skipping  2019030112  already imported.\n",
      "Skipping  2019030212  already imported.\n",
      "Skipping  2019030312  already imported.\n",
      "Skipping  2019030412  already imported.\n",
      "Skipping  2019030512  already imported.\n",
      "Skipping  2019030612  already imported.\n",
      "Skipping  2019030712  already imported.\n",
      "Skipping  2019030812  already imported.\n",
      "Skipping  2019030912  already imported.\n",
      "Skipping  2019031012  already imported.\n",
      "Skipping  2019031112  already imported.\n",
      "Skipping  2019031212  already imported.\n",
      "Skipping  2019031312  already imported.\n",
      "Skipping  2019031412  already imported.\n",
      "Skipping  2019031512  already imported.\n",
      "Skipping  2019031612  already imported.\n",
      "Skipping  2019031712  already imported.\n",
      "Skipping  2019031812  already imported.\n",
      "Skipping  2019031912  already imported.\n",
      "Skipping  2019032012  already imported.\n",
      "Skipping  2019032112  already imported.\n",
      "Skipping  2019032212  already imported.\n",
      "Skipping  2019032312  already imported.\n",
      "Skipping  2019032512  already imported.\n",
      "Skipping  2019032612  already imported.\n",
      "Skipping  2019032712  already imported.\n",
      "Skipping  2019032812  already imported.\n",
      "Skipping  2019032912  already imported.\n",
      "Skipping  2019033012  already imported.\n",
      "Skipping  2019033112  already imported.\n",
      "Skipping  2019040112  already imported.\n",
      "Skipping  2019040212  already imported.\n",
      "Skipping  2019040312  already imported.\n",
      "Skipping  2019040412  already imported.\n",
      "Skipping  2019040512  already imported.\n",
      "Skipping  2019040612  already imported.\n",
      "Skipping  2019040712  already imported.\n",
      "Skipping  2019040812  already imported.\n",
      "Skipping  2019040912  already imported.\n",
      "Skipping  2019041012  already imported.\n",
      "Skipping  2019041112  already imported.\n",
      "Skipping  2019041212  already imported.\n",
      "Skipping  2019041312  already imported.\n",
      "Skipping  2019041412  already imported.\n",
      "Skipping  2019041512  already imported.\n",
      "Skipping  2019041612  already imported.\n",
      "Skipping  2019041712  already imported.\n",
      "Skipping  2019041812  already imported.\n",
      "Skipping  2019041912  already imported.\n",
      "Skipping  2019042012  already imported.\n",
      "Skipping  2019042112  already imported.\n",
      "Skipping  2019042212  already imported.\n",
      "Skipping  2019042312  already imported.\n",
      "Skipping  2019042512  already imported.\n",
      "Skipping  2019042612  already imported.\n",
      "Skipping  2019042712  already imported.\n",
      "Skipping  2019042812  already imported.\n",
      "Skipping  2019042912  already imported.\n",
      "Skipping  2019043012  already imported.\n",
      "Skipping  2019050112  already imported.\n",
      "Skipping  2019050212  already imported.\n",
      "Skipping  2019050312  already imported.\n",
      "Skipping  2019050412  already imported.\n",
      "Skipping  2019050512  already imported.\n",
      "Skipping  2019050612  already imported.\n",
      "Skipping  2019050712  already imported.\n",
      "Skipping  2019050812  already imported.\n",
      "Skipping  2019050912  already imported.\n",
      "Skipping  2019051012  already imported.\n",
      "Skipping  2019051112  already imported.\n",
      "Skipping  2019051212  already imported.\n",
      "Skipping  2019051312  already imported.\n",
      "Skipping  2019051412  already imported.\n",
      "Skipping  2019051512  already imported.\n",
      "Skipping  2019051712  already imported.\n",
      "Skipping  2019051812  already imported.\n",
      "Skipping  2019051912  already imported.\n",
      "Skipping  2019052012  already imported.\n",
      "Skipping  2019052112  already imported.\n",
      "Skipping  2019052212  already imported.\n",
      "Skipping  2019052312  already imported.\n",
      "Skipping  2019052412  already imported.\n",
      "Skipping  2019052512  already imported.\n",
      "Skipping  2019052612  already imported.\n",
      "Skipping  2019052712  already imported.\n",
      "Skipping  2019052812  already imported.\n",
      "Skipping  2019052912  already imported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping  2019053012  already imported.\n",
      "Skipping  2019053112  already imported.\n",
      "Skipping  2019060112  already imported.\n",
      "Skipping  2019060212  already imported.\n",
      "Skipping  2019060312  already imported.\n",
      "Skipping  2019060412  already imported.\n",
      "Skipping  2019060512  already imported.\n",
      "Skipping  2019060612  already imported.\n",
      "Skipping  2019060712  already imported.\n",
      "Skipping  2019060812  already imported.\n",
      "Skipping  2019060912  already imported.\n",
      "Skipping  2019061012  already imported.\n",
      "Skipping  2019061112  already imported.\n",
      "Skipping  2019061212  already imported.\n",
      "Skipping  2019061312  already imported.\n",
      "Skipping  2019061412  already imported.\n",
      "Skipping  2019061512  already imported.\n",
      "Skipping  2019061612  already imported.\n",
      "Skipping  2019061712  already imported.\n",
      "Skipping  2019061812  already imported.\n",
      "Skipping  2019061912  already imported.\n",
      "Skipping  2019062012  already imported.\n",
      "Skipping  2019062112  already imported.\n",
      "Skipping  2019062212  already imported.\n",
      "Skipping  2019062312  already imported.\n",
      "Skipping  2019062412  already imported.\n",
      "Skipping  2019062512  already imported.\n",
      "Skipping  2019062612  already imported.\n",
      "Skipping  2019062712  already imported.\n",
      "Skipping  2019062812  already imported.\n",
      "Skipping  2019062912  already imported.\n",
      "Skipping  2019063012  already imported.\n",
      "Skipping  2019070112  already imported.\n",
      "Skipping  2019070212  already imported.\n",
      "Skipping  2019070312  already imported.\n",
      "Skipping  2019070412  already imported.\n",
      "Skipping  2019070512  already imported.\n",
      "Skipping  2019070612  already imported.\n",
      "Skipping  2019070712  already imported.\n",
      "Skipping  2019070812  already imported.\n",
      "Skipping  2019070912  already imported.\n",
      "Skipping  2019071012  already imported.\n",
      "Skipping  2019071112  already imported.\n",
      "Skipping  2019071212  already imported.\n",
      "Skipping  2019071312  already imported.\n",
      "Skipping  2019071412  already imported.\n",
      "Skipping  2019071512  already imported.\n",
      "Skipping  2019071612  already imported.\n",
      "Skipping  2019071712  already imported.\n",
      "Skipping  2019071812  already imported.\n",
      "Skipping  2019071912  already imported.\n",
      "Skipping  2019072012  already imported.\n",
      "Skipping  2019072112  already imported.\n",
      "Skipping  2019072212  already imported.\n",
      "Skipping  2019072312  already imported.\n",
      "Skipping  2019072412  already imported.\n",
      "Skipping  2019072512  already imported.\n",
      "Skipping  2019072612  already imported.\n",
      "Skipping  2019072712  already imported.\n",
      "Skipping  2019072812  already imported.\n",
      "Skipping  2019072912  already imported.\n",
      "Skipping  2019073012  already imported.\n",
      "Skipping  2019073112  already imported.\n",
      "Skipping  2019080112  already imported.\n",
      "Skipping  2019080212  already imported.\n",
      "Skipping  2019080312  already imported.\n",
      "Skipping  2019080412  already imported.\n",
      "Skipping  2019080512  already imported.\n",
      "Skipping  2019080612  already imported.\n",
      "Skipping  2019080712  already imported.\n",
      "Skipping  2019080812  already imported.\n",
      "Skipping  2019080912  already imported.\n",
      "Skipping  2019081012  already imported.\n",
      "Skipping  2019081112  already imported.\n",
      "Skipping  2019081212  already imported.\n",
      "Skipping  2019081312  already imported.\n",
      "Skipping  2019081412  already imported.\n",
      "Skipping  2019081512  already imported.\n",
      "Skipping  2019081612  already imported.\n",
      "Skipping  2019081712  already imported.\n",
      "Skipping  2019081812  already imported.\n",
      "Skipping  2019081912  already imported.\n",
      "using alternative method for defining times\n",
      "Overwrite existing file: nearest_s2d_1251x4500_304x448.nc \n",
      " You can set reuse_weights=True to save computing time.\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavygofs/forecast/sipn_nc/ARCu0_2019082012_Stereo.nc\n",
      "Regridding  usnavyncep ...\n",
      "Found  328  initialization times.\n",
      "Only updating new files\n",
      "Skipping  2018010112  already imported.\n",
      "Skipping  2018010212  already imported.\n",
      "Skipping  2018010612  already imported.\n",
      "Skipping  2018010712  already imported.\n",
      "Skipping  2018010812  already imported.\n",
      "Skipping  2018010912  already imported.\n",
      "Skipping  2018011312  already imported.\n",
      "Skipping  2018011412  already imported.\n",
      "Skipping  2018011512  already imported.\n",
      "Skipping  2018011612  already imported.\n",
      "Skipping  2018012012  already imported.\n",
      "Skipping  2018012112  already imported.\n",
      "Skipping  2018012212  already imported.\n",
      "Skipping  2018012312  already imported.\n",
      "Skipping  2018012712  already imported.\n",
      "Skipping  2018012912  already imported.\n",
      "Skipping  2018013012  already imported.\n",
      "Skipping  2018020312  already imported.\n",
      "Skipping  2018020412  already imported.\n",
      "Skipping  2018020512  already imported.\n",
      "Skipping  2018020612  already imported.\n",
      "Skipping  2018021012  already imported.\n",
      "Skipping  2018021112  already imported.\n",
      "Skipping  2018021212  already imported.\n",
      "Skipping  2018021312  already imported.\n",
      "Skipping  2018021712  already imported.\n",
      "Skipping  2018021812  already imported.\n",
      "Skipping  2018021912  already imported.\n",
      "Skipping  2018022012  already imported.\n",
      "Skipping  2018022412  already imported.\n",
      "Skipping  2018022512  already imported.\n",
      "Skipping  2018022612  already imported.\n",
      "Skipping  2018022712  already imported.\n",
      "Skipping  2018030312  already imported.\n",
      "Skipping  2018030412  already imported.\n",
      "Skipping  2018030512  already imported.\n",
      "Skipping  2018030612  already imported.\n",
      "Skipping  2018031012  already imported.\n",
      "Skipping  2018031112  already imported.\n",
      "Skipping  2018031212  already imported.\n",
      "Skipping  2018031312  already imported.\n",
      "Skipping  2018031712  already imported.\n",
      "Skipping  2018031812  already imported.\n",
      "Skipping  2018031912  already imported.\n",
      "Skipping  2018032012  already imported.\n",
      "Skipping  2018032412  already imported.\n",
      "Skipping  2018032512  already imported.\n",
      "Skipping  2018032612  already imported.\n",
      "Skipping  2018032712  already imported.\n",
      "Skipping  2018033112  already imported.\n",
      "Skipping  2018040112  already imported.\n",
      "Skipping  2018040212  already imported.\n",
      "Skipping  2018040312  already imported.\n",
      "Skipping  2018040712  already imported.\n",
      "Skipping  2018040812  already imported.\n",
      "Skipping  2018040912  already imported.\n",
      "Skipping  2018041012  already imported.\n",
      "Skipping  2018041412  already imported.\n",
      "Skipping  2018041512  already imported.\n",
      "Skipping  2018041612  already imported.\n",
      "Skipping  2018041712  already imported.\n",
      "Skipping  2018042112  already imported.\n",
      "Skipping  2018042212  already imported.\n",
      "Skipping  2018042312  already imported.\n",
      "Skipping  2018042412  already imported.\n",
      "Skipping  2018042812  already imported.\n",
      "Skipping  2018042912  already imported.\n",
      "Skipping  2018043012  already imported.\n",
      "Skipping  2018050112  already imported.\n",
      "Skipping  2018050512  already imported.\n",
      "Skipping  2018050612  already imported.\n",
      "Skipping  2018050712  already imported.\n",
      "Skipping  2018050812  already imported.\n",
      "Skipping  2018051212  already imported.\n",
      "Skipping  2018051312  already imported.\n",
      "Skipping  2018051412  already imported.\n",
      "Skipping  2018051512  already imported.\n",
      "Skipping  2018051912  already imported.\n",
      "Skipping  2018052012  already imported.\n",
      "Skipping  2018052112  already imported.\n",
      "Skipping  2018052212  already imported.\n",
      "Skipping  2018052612  already imported.\n",
      "Skipping  2018052712  already imported.\n",
      "Skipping  2018052812  already imported.\n",
      "Skipping  2018052912  already imported.\n",
      "Skipping  2018060212  already imported.\n",
      "Skipping  2018060312  already imported.\n",
      "Skipping  2018060412  already imported.\n",
      "Skipping  2018060512  already imported.\n",
      "Skipping  2018060912  already imported.\n",
      "Skipping  2018061012  already imported.\n",
      "Skipping  2018061112  already imported.\n",
      "Skipping  2018061212  already imported.\n",
      "Skipping  2018061612  already imported.\n",
      "Skipping  2018061712  already imported.\n",
      "Skipping  2018061812  already imported.\n",
      "Skipping  2018061912  already imported.\n",
      "Skipping  2018062312  already imported.\n",
      "Skipping  2018062412  already imported.\n",
      "Skipping  2018062512  already imported.\n",
      "Skipping  2018062612  already imported.\n",
      "Skipping  2018063012  already imported.\n",
      "Skipping  2018070112  already imported.\n",
      "Skipping  2018070212  already imported.\n",
      "Skipping  2018070312  already imported.\n",
      "Skipping  2018070712  already imported.\n",
      "Skipping  2018070812  already imported.\n",
      "Skipping  2018070912  already imported.\n",
      "Skipping  2018071012  already imported.\n",
      "Skipping  2018072112  already imported.\n",
      "Skipping  2018072212  already imported.\n",
      "Skipping  2018072312  already imported.\n",
      "Skipping  2018072412  already imported.\n",
      "Skipping  2018072812  already imported.\n",
      "Skipping  2018072912  already imported.\n",
      "Skipping  2018073012  already imported.\n",
      "Skipping  2018073112  already imported.\n",
      "Skipping  2018080412  already imported.\n",
      "Skipping  2018080512  already imported.\n",
      "Skipping  2018080712  already imported.\n",
      "Skipping  2018081112  already imported.\n",
      "Skipping  2018081212  already imported.\n",
      "Skipping  2018081312  already imported.\n",
      "Skipping  2018081412  already imported.\n",
      "Skipping  2018081812  already imported.\n",
      "Skipping  2018081912  already imported.\n",
      "Skipping  2018082012  already imported.\n",
      "Skipping  2018082512  already imported.\n",
      "Skipping  2018082612  already imported.\n",
      "Skipping  2018082712  already imported.\n",
      "Skipping  2018090112  already imported.\n",
      "Skipping  2018090212  already imported.\n",
      "Skipping  2018090312  already imported.\n",
      "Skipping  2018090412  already imported.\n",
      "Skipping  2018090812  already imported.\n",
      "Skipping  2018090912  already imported.\n",
      "Skipping  2018091012  already imported.\n",
      "Skipping  2018091112  already imported.\n",
      "Skipping  2018091512  already imported.\n",
      "Skipping  2018091612  already imported.\n",
      "Skipping  2018091712  already imported.\n",
      "Skipping  2018091812  already imported.\n",
      "Skipping  2018092212  already imported.\n",
      "Skipping  2018092312  already imported.\n",
      "Skipping  2018092412  already imported.\n",
      "Skipping  2018092512  already imported.\n",
      "Skipping  2018092912  already imported.\n",
      "Skipping  2018093012  already imported.\n",
      "Skipping  2018100112  already imported.\n",
      "Skipping  2018100212  already imported.\n",
      "Skipping  2018100612  already imported.\n",
      "Skipping  2018100712  already imported.\n",
      "Skipping  2018100812  already imported.\n",
      "Skipping  2018100912  already imported.\n",
      "Skipping  2018101312  already imported.\n",
      "Skipping  2018101412  already imported.\n",
      "Skipping  2018101512  already imported.\n",
      "Skipping  2018102012  already imported.\n",
      "Skipping  2018102112  already imported.\n",
      "Skipping  2018102212  already imported.\n",
      "Skipping  2018102312  already imported.\n",
      "Skipping  2018102712  already imported.\n",
      "Skipping  2018102812  already imported.\n",
      "Skipping  2018102912  already imported.\n",
      "Skipping  2018103012  already imported.\n",
      "Skipping  2018110312  already imported.\n",
      "Skipping  2018110412  already imported.\n",
      "Skipping  2018110512  already imported.\n",
      "Skipping  2018110612  already imported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping  2018111012  already imported.\n",
      "Skipping  2018111112  already imported.\n",
      "Skipping  2018111212  already imported.\n",
      "Skipping  2018111312  already imported.\n",
      "Skipping  2018111712  already imported.\n",
      "Skipping  2018111812  already imported.\n",
      "Skipping  2018111912  already imported.\n",
      "Skipping  2018112012  already imported.\n",
      "Skipping  2018112412  already imported.\n",
      "Skipping  2018112512  already imported.\n",
      "Skipping  2018112612  already imported.\n",
      "Skipping  2018112712  already imported.\n",
      "Skipping  2018120112  already imported.\n",
      "Skipping  2018120212  already imported.\n",
      "Skipping  2018120312  already imported.\n",
      "Skipping  2018120412  already imported.\n",
      "Skipping  2018120812  already imported.\n",
      "Skipping  2018120912  already imported.\n",
      "Skipping  2018121012  already imported.\n",
      "Skipping  2018121112  already imported.\n",
      "Skipping  2018121512  already imported.\n",
      "Skipping  2018121612  already imported.\n",
      "Skipping  2018121712  already imported.\n",
      "Skipping  2018121812  already imported.\n",
      "Skipping  2018122212  already imported.\n",
      "Skipping  2018122312  already imported.\n",
      "Skipping  2018122412  already imported.\n",
      "Skipping  2018122512  already imported.\n",
      "Skipping  2018122912  already imported.\n",
      "Skipping  2018123012  already imported.\n",
      "Skipping  2018123112  already imported.\n",
      "Skipping  2019010112  already imported.\n",
      "Skipping  2019010512  already imported.\n",
      "Skipping  2019010612  already imported.\n",
      "Skipping  2019010712  already imported.\n",
      "Skipping  2019010812  already imported.\n",
      "Skipping  2019011212  already imported.\n",
      "Skipping  2019011312  already imported.\n",
      "Skipping  2019011412  already imported.\n",
      "Skipping  2019011512  already imported.\n",
      "Skipping  2019011912  already imported.\n",
      "Skipping  2019012012  already imported.\n",
      "Skipping  2019012112  already imported.\n",
      "Skipping  2019012212  already imported.\n",
      "Skipping  2019012612  already imported.\n",
      "Skipping  2019012712  already imported.\n",
      "Skipping  2019012812  already imported.\n",
      "Skipping  2019012912  already imported.\n",
      "Skipping  2019020212  already imported.\n",
      "Skipping  2019020312  already imported.\n",
      "Skipping  2019020412  already imported.\n",
      "Skipping  2019020512  already imported.\n",
      "Skipping  2019020912  already imported.\n",
      "Skipping  2019021012  already imported.\n",
      "Skipping  2019021112  already imported.\n",
      "Skipping  2019021212  already imported.\n",
      "Skipping  2019021612  already imported.\n",
      "Skipping  2019021712  already imported.\n",
      "Skipping  2019021812  already imported.\n",
      "Skipping  2019021912  already imported.\n",
      "Skipping  2019022312  already imported.\n",
      "Skipping  2019022412  already imported.\n",
      "Skipping  2019022512  already imported.\n",
      "Skipping  2019022612  already imported.\n",
      "Skipping  2019030212  already imported.\n",
      "Skipping  2019030312  already imported.\n",
      "Skipping  2019030412  already imported.\n",
      "Skipping  2019030512  already imported.\n",
      "Skipping  2019030912  already imported.\n",
      "Skipping  2019031012  already imported.\n",
      "Skipping  2019031112  already imported.\n",
      "Skipping  2019031212  already imported.\n",
      "Skipping  2019031612  already imported.\n",
      "Skipping  2019031712  already imported.\n",
      "Skipping  2019031812  already imported.\n",
      "Skipping  2019031912  already imported.\n",
      "Skipping  2019032312  already imported.\n",
      "Skipping  2019032412  already imported.\n",
      "Skipping  2019032512  already imported.\n",
      "Skipping  2019032612  already imported.\n",
      "Skipping  2019033012  already imported.\n",
      "Skipping  2019033112  already imported.\n",
      "Skipping  2019040212  already imported.\n",
      "Skipping  2019040612  already imported.\n",
      "Skipping  2019040712  already imported.\n",
      "Skipping  2019040812  already imported.\n",
      "Skipping  2019040912  already imported.\n",
      "Skipping  2019041312  already imported.\n",
      "Skipping  2019041412  already imported.\n",
      "Skipping  2019041512  already imported.\n",
      "Skipping  2019041612  already imported.\n",
      "Skipping  2019042012  already imported.\n",
      "Skipping  2019042112  already imported.\n",
      "Skipping  2019042212  already imported.\n",
      "Skipping  2019042312  already imported.\n",
      "Skipping  2019042712  already imported.\n",
      "Skipping  2019042812  already imported.\n",
      "Skipping  2019042912  already imported.\n",
      "Skipping  2019043012  already imported.\n",
      "Skipping  2019050412  already imported.\n",
      "Skipping  2019050512  already imported.\n",
      "Skipping  2019050612  already imported.\n",
      "Skipping  2019050712  already imported.\n",
      "Skipping  2019051112  already imported.\n",
      "Skipping  2019051212  already imported.\n",
      "Skipping  2019051312  already imported.\n",
      "Skipping  2019051412  already imported.\n",
      "Skipping  2019051812  already imported.\n",
      "Skipping  2019051912  already imported.\n",
      "Skipping  2019052012  already imported.\n",
      "Skipping  2019052112  already imported.\n",
      "Skipping  2019052512  already imported.\n",
      "Skipping  2019052612  already imported.\n",
      "Skipping  2019052712  already imported.\n",
      "Skipping  2019052812  already imported.\n",
      "Skipping  2019060112  already imported.\n",
      "Skipping  2019060212  already imported.\n",
      "Skipping  2019060312  already imported.\n",
      "Skipping  2019060412  already imported.\n",
      "Skipping  2019060812  already imported.\n",
      "Skipping  2019060912  already imported.\n",
      "Skipping  2019061012  already imported.\n",
      "Skipping  2019061112  already imported.\n",
      "Skipping  2019061512  already imported.\n",
      "Skipping  2019061612  already imported.\n",
      "Skipping  2019061712  already imported.\n",
      "Skipping  2019061812  already imported.\n",
      "Skipping  2019062212  already imported.\n",
      "Skipping  2019062312  already imported.\n",
      "Skipping  2019062412  already imported.\n",
      "Skipping  2019062512  already imported.\n",
      "Skipping  2019062912  already imported.\n",
      "Skipping  2019063012  already imported.\n",
      "Skipping  2019070112  already imported.\n",
      "Skipping  2019070212  already imported.\n",
      "Skipping  2019070612  already imported.\n",
      "Skipping  2019070712  already imported.\n",
      "Skipping  2019070812  already imported.\n",
      "Skipping  2019070912  already imported.\n",
      "Skipping  2019071312  already imported.\n",
      "Skipping  2019071412  already imported.\n",
      "Skipping  2019071512  already imported.\n",
      "Skipping  2019071612  already imported.\n",
      "Skipping  2019072012  already imported.\n",
      "Skipping  2019072112  already imported.\n",
      "Skipping  2019072212  already imported.\n",
      "Skipping  2019072312  already imported.\n",
      "Skipping  2019072712  already imported.\n",
      "Skipping  2019072812  already imported.\n",
      "Skipping  2019072912  already imported.\n",
      "Skipping  2019073012  already imported.\n",
      "Skipping  2019080312  already imported.\n",
      "Skipping  2019080412  already imported.\n",
      "Skipping  2019080512  already imported.\n",
      "Skipping  2019080612  already imported.\n",
      "Skipping  2019081012  already imported.\n",
      "Skipping  2019081112  already imported.\n",
      "Skipping  2019081212  already imported.\n",
      "Skipping  2019081312  already imported.\n",
      "Regridding  usnavysipn ...\n",
      "Found  60  initialization times.\n",
      "Only updating new files\n",
      "Skipping  2018050112  already imported.\n",
      "Skipping  2018050212  already imported.\n",
      "Skipping  2018050312  already imported.\n",
      "Skipping  2018050412  already imported.\n",
      "Skipping  2018050512  already imported.\n",
      "Skipping  2018050612  already imported.\n",
      "Skipping  2018050712  already imported.\n",
      "Skipping  2018050812  already imported.\n",
      "Skipping  2018050912  already imported.\n",
      "Skipping  2018051012  already imported.\n",
      "Skipping  2018060212  already imported.\n",
      "Skipping  2018060312  already imported.\n",
      "Skipping  2018060412  already imported.\n",
      "Skipping  2018060512  already imported.\n",
      "Skipping  2018060612  already imported.\n",
      "Skipping  2018060712  already imported.\n",
      "Skipping  2018060812  already imported.\n",
      "Skipping  2018060912  already imported.\n",
      "Skipping  2018061012  already imported.\n",
      "Skipping  2018061112  already imported.\n",
      "Skipping  2018070112  already imported.\n",
      "Skipping  2018070212  already imported.\n",
      "Skipping  2018070312  already imported.\n",
      "Skipping  2018070412  already imported.\n",
      "Skipping  2018070512  already imported.\n",
      "Skipping  2018070612  already imported.\n",
      "Skipping  2018070712  already imported.\n",
      "Skipping  2018070812  already imported.\n",
      "Skipping  2018070912  already imported.\n",
      "Skipping  2018071012  already imported.\n",
      "Skipping  2019050112  already imported.\n",
      "Skipping  2019050212  already imported.\n",
      "Skipping  2019050312  already imported.\n",
      "Skipping  2019050412  already imported.\n",
      "Skipping  2019050512  already imported.\n",
      "Skipping  2019050612  already imported.\n",
      "Skipping  2019050712  already imported.\n",
      "Skipping  2019050812  already imported.\n",
      "Skipping  2019050912  already imported.\n",
      "Skipping  2019051012  already imported.\n",
      "Skipping  2019060112  already imported.\n",
      "Skipping  2019060212  already imported.\n",
      "Skipping  2019060312  already imported.\n",
      "Skipping  2019060512  already imported.\n",
      "Skipping  2019060612  already imported.\n",
      "Skipping  2019060712  already imported.\n",
      "Skipping  2019060812  already imported.\n",
      "Skipping  2019060912  already imported.\n",
      "Skipping  2019061012  already imported.\n",
      "Skipping  2019061112  already imported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using alternative method for defining times\n",
      "Overwrite existing file: nearest_s2d_1251x4500_304x448.nc \n",
      " You can set reuse_weights=True to save computing time.\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavysipn/forecast/sipn_nc/ARCu0_2019070112_Stereo.nc\n",
      "using alternative method for defining times\n",
      "Reuse existing file: nearest_s2d_1251x4500_304x448.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavysipn/forecast/sipn_nc/ARCu0_2019070212_Stereo.nc\n",
      "using alternative method for defining times\n",
      "Reuse existing file: nearest_s2d_1251x4500_304x448.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavysipn/forecast/sipn_nc/ARCu0_2019070312_Stereo.nc\n",
      "using alternative method for defining times\n",
      "Reuse existing file: nearest_s2d_1251x4500_304x448.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavysipn/forecast/sipn_nc/ARCu0_2019070412_Stereo.nc\n",
      "using alternative method for defining times\n",
      "Reuse existing file: nearest_s2d_1251x4500_304x448.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavysipn/forecast/sipn_nc/ARCu0_2019070512_Stereo.nc\n",
      "using alternative method for defining times\n",
      "Reuse existing file: nearest_s2d_1251x4500_304x448.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavysipn/forecast/sipn_nc/ARCu0_2019070612_Stereo.nc\n",
      "using alternative method for defining times\n",
      "Reuse existing file: nearest_s2d_1251x4500_304x448.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavysipn/forecast/sipn_nc/ARCu0_2019070712_Stereo.nc\n",
      "using alternative method for defining times\n",
      "Reuse existing file: nearest_s2d_1251x4500_304x448.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavysipn/forecast/sipn_nc/ARCu0_2019070812_Stereo.nc\n",
      "using alternative method for defining times\n",
      "Reuse existing file: nearest_s2d_1251x4500_304x448.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavysipn/forecast/sipn_nc/ARCu0_2019070912_Stereo.nc\n",
      "using alternative method for defining times\n",
      "Reuse existing file: nearest_s2d_1251x4500_304x448.nc\n",
      "Saved  /home/disk/sipn/nicway/data/model/usnavysipn/forecast/sipn_nc/ARCu0_2019071012_Stereo.nc\n"
     ]
    }
   ],
   "source": [
    "#for model in ['usnavysipn']:\n",
    "for model in all_models:\n",
    "    print('Regridding ', model, '...')\n",
    "    \n",
    "    data_dir = E.model[model][runType]['native']\n",
    "    data_out = E.model[model][runType]['sipn_nc']\n",
    "    model_grid_file = E.model[model]['grid']\n",
    "    \n",
    "    # Files are stored as per time step (about 45 per init_time)\n",
    "    # First parse files to see what unique init_times we have\n",
    "    # ARCu0.08_121_2018042112_t0300.nc\n",
    "    prefix = 'ARCu0'\n",
    "    all_files = glob.glob(os.path.join(data_dir, '*'+prefix+'*.nc'))\n",
    "    if model=='usnavygofs':\n",
    "        init_N = 4\n",
    "    else:\n",
    "        init_N = 2\n",
    "    init_times = list(set([s.split('_')[init_N] for s in all_files]))\n",
    "    \n",
    "    print(\"Found \",len(init_times),\" initialization times.\")\n",
    "    if updateall:\n",
    "        print(\"Updating all files...\")\n",
    "    else:\n",
    "        print(\"Only updating new files\")\n",
    "\n",
    "\n",
    "    weights_flag = False # Flag to set up weights have been created\n",
    "\n",
    "    # Load land/sea mask file\n",
    "    if os.path.basename(model_grid_file)!='MISSING':\n",
    "        ds_mask = xr.open_mfdataset(model_grid_file)\n",
    "    else:\n",
    "        ds_mask = None\n",
    "\n",
    "    for cf in sorted(init_times):\n",
    "        # Check if already imported and skip (unless updateall flag is True)\n",
    "        f_out = os.path.join(data_out, prefix+'_'+cf+'_Stereo.nc') # netcdf file out \n",
    "        if not updateall:\n",
    "            # TODO: Test if the file is openable (not corrupted)\n",
    "            if os.path.isfile(f_out):\n",
    "                print(\"Skipping \", cf, \" already imported.\")\n",
    "                continue # Skip, file already imported\n",
    "\n",
    "        c_files = sorted(glob.glob(os.path.join(data_dir, '*'+prefix+'*_'+cf+'*.nc')))\n",
    "\n",
    "        if len(c_files)==1:\n",
    "            print(\"Skipping because regridding fails when only one time\")\n",
    "            continue \n",
    "\n",
    "        # Some files have a \"tau\" variable that is hours since analysis\n",
    "        try:\n",
    "            ds = xr.open_mfdataset(c_files, concat_dim='time', decode_times=False, autoclose=True)\n",
    "            # Format times\n",
    "            ds.coords['init_time'] = np.datetime64(ds.tau.attrs['time_origin'])\n",
    "            ds.coords['tau'] = ds.tau\n",
    "            ds.swap_dims({'time':'tau'}, inplace=True)\n",
    "            ds.rename({'tau':'fore_time'}, inplace=True)\n",
    "            ds.fore_time.attrs['units'] = 'Forecast offset from initial time'\n",
    "            ds = ds.drop(['time'])\n",
    "            ds.coords['fore_time'] = ds.fore_time.astype('timedelta64[h]') \n",
    "            \n",
    "        # Some do not\n",
    "        except AttributeError:\n",
    "            print('using alternative method for defining times')\n",
    "            ds = xr.open_mfdataset(c_files, concat_dim='time', decode_times=True, autoclose=True)\n",
    "            dt_mod = ds.time.values[1] - ds.time.values[0]\n",
    "            ds.coords['init_time'] = ds.time.values[0] - dt_mod\n",
    "            ds.coords['fore_time'] = ds.time - ds.init_time\n",
    "            ds.swap_dims({'time':'fore_time'}, inplace=True);\n",
    "            ds = ds.drop('time')\n",
    "                        \n",
    "        # Rename variables per esipn guidelines\n",
    "        ds.rename(var_dic, inplace=True);\n",
    "        \n",
    "        # Apply masks (if available)\n",
    "        if ds_mask:\n",
    "            print('found mask')\n",
    "            # land_mask is the fraction of native grid cell that is land\n",
    "            # (1-land_mask) is fraction ocean\n",
    "            # Multiply sic by fraction ocean to get actual native grid cell sic\n",
    "            # Also mask land out where land_mask==1\n",
    "            ds = ds * (1 - ds_mask.land_mask.where(ds_mask.land_mask<1))\n",
    "            \n",
    "        # Add mask variable so conservative regridding works as expected\n",
    "        # DOESN\"T WORK WITH OTHER METHODS!!\n",
    "        #ds['mask'] = ds.sic.isel(fore_time=0).notnull() # Hardcoded variable choice\n",
    "                        \n",
    "        # Calculate regridding matrix\n",
    "        regridder = xe.Regridder(ds, obs_grid, method, periodic=False, reuse_weights=weights_flag)\n",
    "\n",
    "        weights_flag = True # Set true for following loops\n",
    "\n",
    "        # Add NaNs to empty rows of matrix (forces any target cell with ANY source cells containing NaN to be NaN)\n",
    "        #if method=='conservative':\n",
    "        #    regridder = import_data.add_matrix_NaNs(regridder)\n",
    "\n",
    "        # Regrid variables\n",
    "\n",
    "        var_list = []\n",
    "        for cvar in ds.data_vars:\n",
    "            # 0 to NaN hack\n",
    "            #offset = 10\n",
    "            #da_coarse = regridder(ds[cvar]+10)\n",
    "            #da_coarse = da_coarse.where(da_coarse>(offset)) - offset\n",
    "            #var_list.append(da_coarse)\n",
    "            \n",
    "            # When doing nearest neighbor\n",
    "            da_coarse = regridder(ds[cvar])\n",
    "            var_list.append(da_coarse)\n",
    "            \n",
    "        ds_out = xr.merge(var_list)\n",
    "\n",
    "        # Expand dims\n",
    "        ds_out = import_data.expand_to_sipn_dims(ds_out)\n",
    "                \n",
    "        # # Save regridded to netcdf file\n",
    "        ds_out.to_netcdf(f_out)\n",
    "        \n",
    "        ds_out = None # Memory clean up\n",
    "        print('Saved ', f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "if weights_flag:\n",
    "    regridder.clean_weight_file()  # clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sic_all = xr.open_mfdataset(f_out)\n",
    "\n",
    "# # Set up plotting info\n",
    "# cmap_sic = matplotlib.colors.ListedColormap(sns.color_palette(\"Blues\", 10))\n",
    "# cmap_sic.set_bad(color = 'red')\n",
    "\n",
    "# # Plot original projection\n",
    "# plt.figure(figsize=(20,10))\n",
    "# ax1 = plt.axes(projection=ccrs.PlateCarree())\n",
    "# ds_p = ds.sic.isel(fore_time=79)\n",
    "# ds_p.plot.pcolormesh(ax=ax1, x='lon', y='lat', \n",
    "#                                  vmin=0, vmax=1,\n",
    "#                                  cmap=matplotlib.colors.ListedColormap(sns.color_palette(\"Blues\", 10)),\n",
    "#                     transform=ccrs.PlateCarree());\n",
    "# ax1.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n",
    "# gl = ax1.gridlines(crs=ccrs.PlateCarree(), linestyle='-')\n",
    "# gl.xlabels_bottom = True\n",
    "# gl.ylabels_left = True\n",
    "# gl.xformatter = LONGITUDE_FORMATTER\n",
    "# gl.yformatter = LATITUDE_FORMATTER\n",
    "# ax1.coastlines(linewidth=0.75, color='black', resolution='50m');\n",
    "\n",
    "# # Plot SIC on target projection\n",
    "# (f, ax1) = ice_plot.polar_axis()\n",
    "# ds_p2 = sic_all.sic.isel(init_time=0).isel(fore_time=79).isel(ensemble=0)\n",
    "# ds_p2.plot.pcolormesh(ax=ax1, x='lon', y='lat', \n",
    "#                                      transform=ccrs.PlateCarree(),\n",
    "#                                      cmap=cmap_sic)\n",
    "# ax1.set_title('Target Grid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
