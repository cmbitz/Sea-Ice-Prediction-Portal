{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This code is part of the SIPN2 project focused on improving sub-seasonal to seasonal predictions of Arctic Sea Ice. \n",
    "If you use this code for a publication or presentation, please cite the reference in the README.md on the\n",
    "main page (https://github.com/NicWayand/ESIO). \n",
    "\n",
    "Questions or comments should be addressed to nicway@uw.edu\n",
    "\n",
    "Copyright (c) 2018 Nic Wayand\n",
    "\n",
    "GNU General Public License v3.0\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "Plot forecast maps with all available models.\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import struct\n",
    "import os\n",
    "import xarray as xr\n",
    "import glob\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import seaborn as sns\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "from esio import EsioData as ed\n",
    "from esio import ice_plot\n",
    "from esio import import_data\n",
    "from esio import metrics\n",
    "import dask\n",
    "import xskillscore as xs\n",
    "\n",
    "# General plotting settings\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context(\"talk\", font_scale=.8, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "# client = Client(n_workers=2)\n",
    "# client = Client()\n",
    "# client\n",
    "dask.config.set(scheduler='threads')  # overwrite default with threaded scheduler\n",
    "# dask.config.set(scheduler='processes')  # overwrite default with threaded scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "pred_year = 2018 # Prediction year\n",
    "Y_Start = 1979\n",
    "Y_End = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Load in Data\n",
    "#############################################################\n",
    "\n",
    "E = ed.EsioData.load()\n",
    "mod_dir = E.model_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most recent obs\n",
    "ds_81 = xr.open_mfdataset(E.obs['NSIDC_0081']['sipn_nc']+'_yearly/*.nc', concat_dim='time', autoclose=True, parallel=True)\n",
    "doyall = metrics.get_DOY(ds_81.time)\n",
    "ds_81.coords['doy'] = xr.DataArray(doyall, dims='time', coords={'time':ds_81.time})\n",
    "\n",
    "# Get mean sic by DOY\n",
    "print(\"Need up update to 1979-2017 mean\")\n",
    "mean_1980_2010_sic = xr.open_dataset(os.path.join(E.obs_dir, 'NSIDC_0051', 'agg_nc', 'mean_1980_2010_sic.nc')).sic\n",
    "\n",
    "end_date = datetime.datetime.now()\n",
    "end_date = datetime.datetime(end_date.year, end_date.month, end_date.day) # Set hour min sec to 0. \n",
    "start_date = datetime.datetime(end_date.year, 1, 1) # Set hour min sec to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in alphas\n",
    "alpha_cdoy = xr.open_mfdataset('/home/disk/sipn/nicway/data/model/dampedAnomalyTrend/forecast/param/'+str(pred_year)+'_*.nc',\n",
    "                              concat_dim='doy', autoclose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_cdoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Damped Anomaly from Climatological Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmod = 'dampedAnomaly'\n",
    "# runType = 'forecast'\n",
    "\n",
    "# # Loop through current year\n",
    "# for ctime in ds_81.time.sel(time=slice(start_date,end_date)):\n",
    "    \n",
    "#     c_sic = ds_81.sic.sel(time=ctime)\n",
    "#     cdoy = c_sic.doy.item()\n",
    "\n",
    "#     # Calculate most recent anomaly\n",
    "#     c_anomaly = c_sic - mean_1980_2010_sic.sel(time=cdoy)\n",
    "\n",
    "#     da_l = []\n",
    "#     # Fore each forecast period (here 7 days)\n",
    "#     fore_cast_interval = 7\n",
    "#     for fore_index in np.arange(0,60,1):\n",
    "#         fore_anomaly = (alpha_cdoy.sel(doy=cdoy).alpha**fore_index) * c_anomaly\n",
    "        \n",
    "#         valid_doy = cdoy + fore_index * fore_cast_interval\n",
    "#         # Wrap around if > 366\n",
    "#         if valid_doy > mean_1980_2010_sic.time.max().values:\n",
    "#             valid_doy = valid_doy - mean_1980_2010_sic.time.max().values\n",
    "         \n",
    "#         # Get SIC by adding anomaly to the mean SIC\n",
    "#         fore_sic = fore_anomaly + mean_1980_2010_sic.sel(time=valid_doy)\n",
    "        \n",
    "#         # Force prediction SIC to be between 0-1\n",
    "#         ocnmask = fore_sic.notnull()\n",
    "#         fore_sic = fore_sic.where(fore_sic >= 0, other=0).where(ocnmask)\n",
    "#         fore_sic = fore_sic.where(fore_sic <= 1, other=1).where(ocnmask)\n",
    "\n",
    "#         # Add cords\n",
    "#         fore_sic.coords['fore_time'] = np.timedelta64(int(fore_index*fore_cast_interval),'D')\n",
    "#         da_l.append(fore_sic)\n",
    "\n",
    "#     da_sic = xr.concat(da_l, dim='fore_time')    \n",
    "#     da_sic.coords['init_time'] = c_sic.time\n",
    "    \n",
    "#     da_sic = da_sic.drop(['xm','ym','lag','doy','hole_mask','time'])\n",
    "\n",
    "#     da_sic.name = 'sic'\n",
    "\n",
    "#     da_sic = import_data.expand_to_sipn_dims(da_sic)\n",
    "    \n",
    "#     da_sic = da_sic.rename({'x':'nj','y':'ni'})\n",
    "            \n",
    "#     file_out = os.path.join(mod_dir, cmod, runType, 'sipn_nc', pd.to_datetime(da_sic.init_time.item()).strftime('%Y-%m-%d')+'.nc')\n",
    "#     da_sic.to_netcdf(file_out)\n",
    "#     print(\"Saved file:\",file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Damped Anomaly from Climatological Trend prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod = 'dampedAnomalyTrend'\n",
    "runType = 'forecast'\n",
    "\n",
    "\n",
    "# Climatology model trend\n",
    "all_files = os.path.join(mod_dir,'climatology',runType,'sipn_nc', str(end_date.year)+'*.nc')\n",
    "files = glob.glob(all_files)\n",
    "obs_clim_model = xr.open_mfdataset(sorted(files), \n",
    "        chunks={'time': 30, 'x': 304, 'y': 448},  \n",
    "         concat_dim='time', autoclose=True, parallel=True)\n",
    "obs_clim_model = obs_clim_model['sic']\n",
    "obs_clim_model = obs_clim_model.swap_dims({'time':'doy'})\n",
    "obs_clim_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plots = False # Need to uncomment xr.exit() below to stop on first doy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UpdateAll = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through current year\n",
    "for ctime in ds_81.time.sel(time=slice(start_date,end_date)):\n",
    "    file_out = os.path.join(mod_dir, cmod, runType, 'sipn_nc', pd.to_datetime(ctime.time.values).strftime('%Y-%m-%d')+'.nc')\n",
    "    \n",
    "    # Only calc if it doesn't exist\n",
    "    if os.path.isfile(file_out) & ~UpdateAll:\n",
    "        continue\n",
    "    \n",
    "    c_sic = ds_81.sic.sel(time=ctime)\n",
    "    cdoy = c_sic.doy.item()\n",
    "\n",
    "    # Calculate most recent anomaly from predicted trend\n",
    "    c_anomaly = c_sic - obs_clim_model.sel(doy=cdoy)\n",
    "    c_anomaly = c_anomaly.drop(['time','doy']) #mean_1980_2010_sic.sel(time=cdoy)\n",
    "\n",
    "    da_l = []\n",
    "    # For each forecast period (here 7 days)\n",
    "    fore_cast_interval = 1\n",
    "    alpha_lead_time = 7.0 # days that the alpha corr was calculated for\n",
    "    for fore_days in np.arange(0,366,1):\n",
    "        fore_anomaly = (alpha_cdoy.sel(doy=cdoy).alpha**(fore_days/alpha_lead_time)) * c_anomaly\n",
    "        \n",
    "        valid_doy = cdoy + fore_days\n",
    "        # Keep  range 1-365\n",
    "        valid_doy = ((valid_doy-1)%365)+1\n",
    "\n",
    "        # Get predicted SIC by adding damped anomaly with SIC predicted by trend through historical period\n",
    "        fore_sic = fore_anomaly + obs_clim_model.sel(doy=valid_doy).drop('doy')\n",
    "        \n",
    "        # Force prediction SIC to be between 0-1\n",
    "        ocnmask = fore_sic.notnull()\n",
    "        fore_sic = fore_sic.where(fore_sic >= 0, other=0).where(ocnmask)\n",
    "        fore_sic = fore_sic.where(fore_sic <= 1, other=1).where(ocnmask)\n",
    "\n",
    "        # Add cords\n",
    "        fore_sic.coords['fore_time'] = np.timedelta64(int(fore_days),'D')\n",
    "        da_l.append(fore_sic)\n",
    "        \n",
    "#         xr.exit()\n",
    "\n",
    "    da_sic = xr.concat(da_l, dim='fore_time')    \n",
    "    da_sic.coords['init_time'] = c_sic.time\n",
    "    \n",
    "    da_sic = da_sic.drop(['xm','ym','lag','doy','hole_mask','time'])\n",
    "\n",
    "    da_sic.name = 'sic'\n",
    "\n",
    "    da_sic = import_data.expand_to_sipn_dims(da_sic)\n",
    "    \n",
    "    da_sic = da_sic.rename({'x':'nj','y':'ni'})\n",
    "            \n",
    "    \n",
    "    da_sic.to_netcdf(file_out)\n",
    "    print(\"Saved file:\",file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test plots for presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_plots:\n",
    "    fig_dir = '/home/disk/sipn/nicway/Nic/figures/pres/A'\n",
    "\n",
    "    cmap_diff_2 = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"white\",\"blue\"])\n",
    "    cmap_diff_2.set_bad(color = 'lightgrey')\n",
    "    cmap_sic = matplotlib.colors.ListedColormap(sns.color_palette(\"Blues_r\", 10))\n",
    "    cmap_sic.set_bad(color = 'lightgrey')\n",
    "\n",
    "    sns.set_context(\"talk\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "    (f, ax) = ice_plot.polar_axis()\n",
    "    obs_clim_model.sel(doy=valid_doy).drop('doy').plot(ax=ax, \n",
    "                                            x='lon', y='lat', \n",
    "                                         transform=ccrs.PlateCarree(),cmap=cmap_sic,\n",
    "                                                      cbar_kwargs={'label':'Sea Ice Concentration (-)'})\n",
    "    plt.title('')\n",
    "    f_out = os.path.join(fig_dir,'Linear_Trend.png')\n",
    "    f.savefig(f_out,bbox_inches='tight', dpi=300)\n",
    "\n",
    "    sns.set_context(\"talk\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "    (f, ax) = ice_plot.polar_axis()\n",
    "    c_anomaly.plot(ax=ax, \n",
    "                        x='lon', y='lat', \n",
    "                     transform=ccrs.PlateCarree(),cmap=cmap_diff_2,\n",
    "                                  cbar_kwargs={'label':'SIC Anomaly'})\n",
    "    plt.title('')\n",
    "    f_out = os.path.join(fig_dir,'Anomoly.png')\n",
    "    f.savefig(f_out,bbox_inches='tight', dpi=300)\n",
    "\n",
    "    sns.set_context(\"talk\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "    (f, ax) = ice_plot.polar_axis()\n",
    "    alpha_cdoy.sel(doy=cdoy).alpha.plot(ax=ax, \n",
    "                        x='lon', y='lat', \n",
    "                     transform=ccrs.PlateCarree(),cmap=cmap_diff_2,\n",
    "                                  cbar_kwargs={'label':'Lag-1 correlation'})\n",
    "    plt.title('')\n",
    "    f_out = os.path.join(fig_dir,'Alpha.png')\n",
    "    f.savefig(f_out,bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "    sns.set_context(\"talk\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "    (f, ax) = ice_plot.polar_axis()\n",
    "    fore_sic.plot(ax=ax, \n",
    "                        x='lon', y='lat', \n",
    "                     transform=ccrs.PlateCarree(),cmap=cmap_sic,\n",
    "                                                      cbar_kwargs={'label':'Sea Ice Concentration (-)'})\n",
    "    plt.title('')\n",
    "    f_out = os.path.join(fig_dir,'DampedTrend_Forecast.png')\n",
    "    f.savefig(f_out,bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare forecasts to check they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmod = 'climatology' # 1979-2017\n",
    "# runType = 'forecast'\n",
    "\n",
    "# all_files = os.path.join(mod_dir,cmod,runType,'sipn_nc', str(end_date.year)+'*.nc')\n",
    "# files = glob.glob(all_files)\n",
    "\n",
    "# climatology = xr.open_mfdataset(sorted(files), \n",
    "#         chunks={'time': 30, 'x': 304, 'y': 448},  \n",
    "#          concat_dim='time', autoclose=True, parallel=True)\n",
    "\n",
    "\n",
    "\n",
    "# # cmod = 'dampedAnomaly'\n",
    "# # runType = 'forecast'\n",
    "\n",
    "# # all_files = os.path.join(mod_dir,cmod,runType,'sipn_nc', str(end_date.year)+'*.nc')\n",
    "# # files = glob.glob(all_files)\n",
    "\n",
    "# # dampedAnomaly = xr.open_mfdataset(sorted(files), \n",
    "# #         chunks={'nj': 304, 'ni': 448},  \n",
    "# #          concat_dim='init_time', autoclose=True, parallel=True)\n",
    "\n",
    "# cmod = 'dampedAnomalyTrend'\n",
    "\n",
    "# all_files = os.path.join(mod_dir,cmod,runType,'sipn_nc', str(end_date.year)+'*.nc')\n",
    "# files = glob.glob(all_files)\n",
    "\n",
    "# dampedAnomalyTrend = xr.open_mfdataset(sorted(files), \n",
    "#         chunks={'nj': 304, 'ni': 448},  \n",
    "#          concat_dim='init_time', autoclose=True, parallel=True)\n",
    "\n",
    "# # Calc SIE\n",
    "\n",
    "\n",
    "\n",
    "# climatology_agg = climatology.sic.sum(dim=['x','y'])\n",
    "\n",
    "# # dampedAnomaly_agg = dampedAnomaly.sic.sum(dim=['nj','ni']).isel(ensemble=0)\n",
    "# # dampedAnomaly_agg = import_data.get_valid_time(dampedAnomaly_agg)\n",
    "\n",
    "# dampedAnomalyTrend_agg = dampedAnomalyTrend.sic.sum(dim=['nj','ni']).isel(ensemble=0)\n",
    "# dampedAnomalyTrend_agg = import_data.get_valid_time(dampedAnomalyTrend_agg)\n",
    "\n",
    "# # Get 1980-2010 Mean\n",
    "# currentYearTime = [np.datetime64('2018-01-01') + np.timedelta64(int(x-1),'D') for x in mean_1980_2010_sic.time.values]\n",
    "# mean_1980_2010_sic.coords['valid_time'] =  xr.DataArray(currentYearTime, dims='time', coords={'time':mean_1980_2010_sic.time})\n",
    "# mean_1980_2010_sic_modified = mean_1980_2010_sic.swap_dims({'time':'valid_time'})\n",
    "# mean_1980_2010_sic_agg = mean_1980_2010_sic.sum(dim=['x','y'])\n",
    "\n",
    "# # Get 2018 obs\n",
    "# target_year_obs = ds_81.sic.sel(time=slice('2018-01-01',end_date)).sum(dim=['x','y'])\n",
    "# target_year_obs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Get ylims\n",
    "# vmin = np.min([climatology_agg.min(), mean_1980_2010_sic_agg.min(), target_year_obs.min()])\n",
    "# vmax = np.max([climatology_agg.max(), mean_1980_2010_sic_agg.max(), target_year_obs.max()])\n",
    "# vmin = vmin - (vmax-vmin)*.1\n",
    "# vmax = vmax + (vmax-vmin)*.1\n",
    "\n",
    "# (vmin, vmax)\n",
    "\n",
    "# mean_1980_2010_sic_agg\n",
    "\n",
    "# f = plt.figure(figsize=(10,8))\n",
    "# # Plot climatological trend\n",
    "# climatology_agg.plot(color='k', label='1979-2017 trend', linewidth=5)\n",
    "# # Plot climatological mean\n",
    "# mean_1980_2010_sic_agg.swap_dims({'time':'valid_time'}).plot(color='m', label='1980-2010 mean', linewidth=5)\n",
    "# # Plot target year obs\n",
    "# target_year_obs.plot(color='b', label='2018 Observations')\n",
    "# addleg = True\n",
    "# for it in dampedAnomalyTrend_agg.init_time.values[0::30]:\n",
    "\n",
    "#     Y = dampedAnomalyTrend_agg.sel(init_time=it)\n",
    "#     plt.plot(Y.valid_time, Y.values, color='g', label='Damped Anomaly to 1979-2017 trend')\n",
    "    \n",
    "#     if addleg:\n",
    "#         plt.legend()\n",
    "#         addleg = False\n",
    "\n",
    "# plt.ylim([vmin,vmax])\n",
    "# plt.ylabel('*Extent* as sum of sic')\n",
    "\n",
    "# f_out = os.path.join('/home/disk/sipn/nicway/Nic/figures/pres/A','damped_example.png')\n",
    "# f.savefig(f_out,bbox_inches='tight', dpi=300)\n",
    "\n",
    "# M1 = dampedAnomalyTrend.sel(init_time=it).isel(fore_time=0, ensemble=0).sic\n",
    "# M1.plot()\n",
    "\n",
    "# O1 = ds_81.sic.sel(time=it)\n",
    "# O1.plot()\n",
    "\n",
    "# M1 = M1.rename({'ni':'y','nj':'x'})\n",
    "\n",
    "# M1\n",
    "\n",
    "# O1\n",
    "\n",
    "# (M1-O1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.4 esio",
   "language": "python",
   "name": "esio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
